{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Creating high-resolution Landcover data using Machine Learning </h1>\n",
    "\n",
    "In this notebook, we train a TensorFlow model to fit Landsat 8 bands to a low-resolution landcover map. Then, we use that model on the high-resolution Landsat data to create a high-resolution landcover map. In essence, we are using TensorFlow to <a href=\"https://gisclimatechange.ucar.edu/question/63\">statistically downscale</a> the landcover data (note that the term \"downscaling\" is counterintuitive -- downscaling an image increases its resolution or upsamples it).\n",
    "\n",
    "<div id=\"toc\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Preprocessing using Cloud Dataflow </h2>\n",
    "\n",
    "Cloud Dataflow can scale up and simplify preprocessing in Cloud ML.  We'll need to read the Geotiffs and then merge them in such a way that all the data corresponding to a pixel becomes a single TFRecord. We'll also need to scale the pixel values to lie in the range [0,1]. If you do this sort of thing naively, you'll run out of memory or burn through your wallet -- the total size of the images alone is 25 GB.  Trying to fit it all in memory would require machines with 3-4 times more RAM.\n",
    "\n",
    "We'll use Cloud Dataflow to distribute the preprocessing onto an autoscaled cluster of machines with 3 GB of RAM each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# a Python generator that packs all the training data line-by-line\n",
    "def get_next_line(SMALL_SAMPLE):\n",
    "  '''\n",
    "      return (lineno, linedata, featnames)\n",
    "      where linedata is a 2D array with first dimension being feature# and second dimension column in image \n",
    "  '''  \n",
    "  import osgeo.gdal as gdal\n",
    "  import struct\n",
    "  import os\n",
    "  import subprocess\n",
    "  \n",
    "  # The gdal library can not read from CloudStorage, so this class downloads the data to local VM\n",
    "  class LandsatReader():\n",
    "   def __init__(self, gsfile, destdir='./'):\n",
    "      self.gsfile = gsfile\n",
    "      self.dest = os.path.join(destdir, os.path.basename(self.gsfile))\n",
    "      if os.path.exists(self.dest):\n",
    "        print 'Using already existing {}'.format(self.dest)\n",
    "      else:\n",
    "        print 'Getting {0} to {1} '.format(self.gsfile, self.dest)\n",
    "        ret = subprocess.check_call(['gsutil', 'cp', self.gsfile, self.dest])\n",
    "      self.dataset = gdal.Open( self.dest, gdal.GA_ReadOnly )\n",
    "   def __exit__(self, exc_type=None, exc_val=None, exc_tb=None):\n",
    "      os.remove( self.dest ) # cleanup  \n",
    "   def ds(self):\n",
    "      return self.dataset\n",
    "\n",
    "  # open all the necessary files\n",
    "  input_dir = 'gs://mdh-test/landsat-ml/'\n",
    "  featnames = ['b{}'.format(band) for band in xrange(1,8)] # 8\n",
    "  filenames = [os.path.join(input_dir, 'landsat8-{}.tif'.format(band)) for band in featnames]\n",
    "  filenames.append(os.path.join(input_dir, 'srtm-elevation.tif')); featnames.append('elev')\n",
    "  filenames.append(os.path.join(input_dir, 'mcd12-labels.tif')); featnames.append('landcover')\n",
    "  readers = [LandsatReader(filename) for filename in filenames]\n",
    "  bands = [reader.ds().GetRasterBand(1) for reader in readers] \n",
    "  print \"Opened \", filenames\n",
    "      \n",
    "  # read one row of each the images and yield them\n",
    "  ncols = bands[0].XSize\n",
    "  nrows = bands[0].YSize\n",
    "  if SMALL_SAMPLE:\n",
    "    nrows_to_read = 200\n",
    "    ncols_to_read = 1000\n",
    "  else:\n",
    "    nrows_to_read = nrows\n",
    "    ncols_to_read = ncols\n",
    "  print \"Reading \", nrows_to_read, \"x\", ncols_to_read, \" from \", nrows, 'x', ncols, ' images corresponding to ', featnames\n",
    "  packformat = 'f' * ncols\n",
    "  for line in xrange(0, nrows_to_read):\n",
    "        line_data = [struct.unpack(packformat, band.ReadRaster(0, line, ncols, 1, ncols, 1, gdal.GDT_Float32)) for band in bands]\n",
    "        yield (line, line_data, featnames, ncols_to_read)\n",
    "      \n",
    "def get_features_from_line(args):\n",
    "  '''\n",
    "      return (1, dict)  or (0, dict)\n",
    "      where the first number is 1 or 0 depending on whether this row belongs to training (1)\n",
    "      or eval (0) partition.\n",
    "      dict is the set of features formed from pixels from all the bands\n",
    "  ''' \n",
    "  (line, line_data, featnames, ncols_to_read) = args\n",
    "  if line_data:\n",
    "    for col in xrange(0, ncols_to_read):\n",
    "          featdict = {'rowcol': '{},{}'.format(line,col)}\n",
    "          for f in xrange(0, len(featnames)):\n",
    "            featdict[featnames[f]] = line_data[f][col]\n",
    "          featdict['landcover'] = '{}'.format(int(featdict['landcover']+0.5))\n",
    "          yield ( 0 if (line+col)%3==0 else 1, featdict )    # 1/3 are eval\n",
    "\n",
    "def get_partition(group_and_featdict, nparts):\n",
    "  (is_train, featdict) = group_and_featdict\n",
    "  return is_train # 0 or 1\n",
    "\n",
    "def get_featdict(group_and_featdict):\n",
    "  (is_train, featdict) = group_and_featdict\n",
    "  return featdict\n",
    "\n",
    "def run_preprocessing(BUCKET=None, PROJECT=None):\n",
    "  import os\n",
    "  import numpy as np\n",
    "  import apache_beam as beam\n",
    "  import google.cloud.ml as ml\n",
    "  import google.cloud.ml.io as io\n",
    "  import google.cloud.ml.features as features\n",
    "\n",
    "  # small sample locally; full dataset on cloud\n",
    "  if BUCKET is None or PROJECT is None:\n",
    "    SMALL_SAMPLE = True\n",
    "    OUTPUT_DIR = './landcover_preproc'\n",
    "    RUNNER = 'DirectPipelineRunner'\n",
    "  else:\n",
    "    SMALL_SAMPLE = False\n",
    "    OUTPUT_DIR = 'gs://{0}/landcover/preproc'.format(BUCKET)\n",
    "    RUNNER = 'DataflowPipelineRunner'\n",
    "  #\n",
    "  \n",
    "  pipeline = beam.Pipeline(argv=['--project', PROJECT,\n",
    "                               '--runner', RUNNER,\n",
    "                               '--job_name', 'landcover',\n",
    "                               '--extra_package', ml.sdk_location,\n",
    "                               '--max_num_workers', '10',\n",
    "                               '--no_save_main_session', 'True',  # to prevent pickling and uploading Datalab itself!\n",
    "                               '--setup_file', './preproc/setup.py',  # for gdal installation on the cloud -- see CUSTOM_COMMANDS in setup.py\n",
    "                               '--staging_location', 'gs://{0}/landcover/staging'.format(BUCKET),\n",
    "                               '--temp_location', 'gs://{0}/landcover/temp'.format(BUCKET)])\n",
    "        \n",
    "  print ml.sdk_location\n",
    "  (evalg, traing) = (pipeline \n",
    "     | beam.Create([SMALL_SAMPLE]) # make the generator function like a source\n",
    "     | beam.FlatMap(get_next_line)\n",
    "     | beam.FlatMap(get_features_from_line) # (is_train, featdict)\n",
    "     | beam.Partition(get_partition, 2)\n",
    "  )  # eval, train both contain (is_train, featdict)\n",
    "  eval = evalg | 'eval_features' >> beam.Map(get_featdict)\n",
    "  train = traing | 'train_features' >> beam.Map(get_featdict)\n",
    "  \n",
    "  class LandcoverFeatures(object):\n",
    "    key = features.key('rowcol')\n",
    "    landcover = features.target('landcover').discrete()  # classification problem\n",
    "    inputbands = [\n",
    "      features.numeric('b1').scale(),\n",
    "      features.numeric('b2').scale(),\n",
    "      features.numeric('b3').scale(),\n",
    "      features.numeric('b4').scale(),\n",
    "      features.numeric('b5').scale(),\n",
    "      features.numeric('b6').scale(),\n",
    "      features.numeric('b7').scale(),\n",
    "      #features.numeric('el').discretize(buckets=[1,5001,50], sparse=True),  # elevation\n",
    "    ]\n",
    "  feature_set = LandcoverFeatures()\n",
    "  (metadata, train_features, eval_features) = ((train, eval) |\n",
    "   'Preprocess' >> ml.Preprocess(feature_set))\n",
    "  (metadata\n",
    "     | 'SaveMetadata'\n",
    "     >> io.SaveMetadata(os.path.join(OUTPUT_DIR, 'metadata.yaml')))\n",
    "  (train_features\n",
    "     | 'WriteTraining'\n",
    "     >> io.SaveFeatures(os.path.join(OUTPUT_DIR, 'features_train')))\n",
    "  (eval_features\n",
    "     | 'WriteEval'\n",
    "     >> io.SaveFeatures(os.path.join(OUTPUT_DIR, 'features_eval')))\n",
    "  pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Create ML model using TensorFlow </h2>\n",
    "\n",
    "I cheated here. I simply took the <a href=\"https://github.com/GoogleCloudPlatform/cloudml-samples/tree/master/iris\">Cloud ML sample for Iris classification</a> and copied it into my repo.  The only change I had to make was to three fields, changing:\n",
    "<pre>\n",
    "KEY_FEATURE_COLUMN = 'key'\n",
    "TARGET_FEATURE_COLUMN = 'species'\n",
    "REAL_VALUED_FEATURE_COLUMNS = 'measurements'\n",
    "</pre>\n",
    "to\n",
    "<pre>\n",
    "KEY_FEATURE_COLUMN = 'key'\n",
    "TARGET_FEATURE_COLUMN = 'landcover'\n",
    "REAL_VALUED_FEATURE_COLUMNS = 'inputbands'\n",
    "</pre>\n",
    "Essentially, my new values match what I had in the class LandcoverFeatures during preprocessing (see above).  This is needed because that's what now encoded in the tfrecord files the preprocessing step wrote out.\n",
    "\n",
    "The model itself is a neural network with 2 hidden layers. The Iris sample uses the tf.learn API. It is a classification network, and the sample does all the saving, exporting, distribution, etc. All my inputs are like the Iris sample in that they are all real-valued columns. Like in the Iris example, the target takes only one value -- a landcover that is brushland can not also be forest. So, I'm relatively safe in reusing the Iris model as-is.  Of course, I should probably do some feature engineering, by calculating normalized differences, for example. But for now, the Iris sample will suffice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "landcover:\r\n",
      "total 8\r\n",
      "-rw-r--r-- 1 root root  746 Nov  3 18:28 setup.py\r\n",
      "drwxr-xr-x 2 root root 4096 Nov  3 23:07 trainer\r\n",
      "\r\n",
      "landcover/trainer:\r\n",
      "total 24\r\n",
      "-rw-r--r-- 1 root root  677 Nov  3 21:54 __init__.py\r\n",
      "-rw-r--r-- 1 root root 9176 Nov  3 23:07 task.py\r\n",
      "-rw-r--r-- 1 root root 5553 Nov  3 22:51 util.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lR landcover"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Train model locally using Cloud ML </h2>\n",
    "\n",
    "Let's train the model locally on a subset of the data to ensure that we get things right. Then, we can train on the cloud with all of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://cloud-ml/sdk/cloudml-0.1.6-alpha.dataflow.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Direct usage of TextFileSink is deprecated. Please use 'textio.WriteToText()' instead of directly instantiating a TextFileSink object.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using already existing ./landsat8-b1.tif\n",
      "Using already existing ./landsat8-b2.tif\n",
      "Using already existing ./landsat8-b3.tif\n",
      "Using already existing ./landsat8-b4.tif\n",
      "Using already existing ./landsat8-b5.tif\n",
      "Using already existing ./landsat8-b6.tif\n",
      "Using already existing ./landsat8-b7.tif\n",
      "Using already existing ./srtm-elevation.tif\n",
      "Using already existing ./mcd12-labels.tif\n",
      "Opened  ['gs://mdh-test/landsat-ml/landsat8-b1.tif', 'gs://mdh-test/landsat-ml/landsat8-b2.tif', 'gs://mdh-test/landsat-ml/landsat8-b3.tif', 'gs://mdh-test/landsat-ml/landsat8-b4.tif', 'gs://mdh-test/landsat-ml/landsat8-b5.tif', 'gs://mdh-test/landsat-ml/landsat8-b6.tif', 'gs://mdh-test/landsat-ml/landsat8-b7.tif', 'gs://mdh-test/landsat-ml/srtm-elevation.tif', 'gs://mdh-test/landsat-ml/mcd12-labels.tif']\n",
      "Reading  200 x 1000  from  16384 x 16384  images corresponding to  ['b1', 'b2', 'b3', 'b4', 'b5', 'b6', 'b7', 'elev', 'landcover']\n"
     ]
    }
   ],
   "source": [
    "# process a small sample (200k points) by running the preprocessing locally\n",
    "# if your Datalab instance can't handle this, reduce the sample size by changing the preprocessing code\n",
    "# (look for nrows_read and change it from 200 to perhaps 20)\n",
    "# alternately, if you followed the codelab instructions to launch Datalab on a GCE, change the machine\n",
    "# type in instance_details.sh to n1-highmem-2   (should take about 5 minutes on n1-highmem-2)\n",
    "import shutil\n",
    "shutil.rmtree('landcover_preproc', ignore_errors=True)\n",
    "run_preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 7004\r\n",
      "-rw-r--r-- 1 root root 2422582 Nov  4 17:00 features_eval-00000-of-00001.tfrecord.gz\r\n",
      "-rw-r--r-- 1 root root 4740616 Nov  4 17:00 features_train-00000-of-00001.tfrecord.gz\r\n",
      "-rw-r--r-- 1 root root    2086 Nov  4 16:59 metadata.yaml\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l /content/training-data-analyst/blogs/landsat-ml/landcover_preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "landcover/\n",
      "landcover/trainer/\n",
      "landcover/trainer/task.py\n",
      "landcover/trainer/util.py\n",
      "landcover/trainer/__init__.py\n",
      "landcover/setup.py\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "rm -rf /content/training-data-analyst/blogs/landsat-ml/landcover_trained\n",
    "tar cvfz landcover.tgz landcover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>Job Running...</p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/_nocachecontent/master\" target=\"_blank\">master log</a>&nbsp;&nbsp;"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "master: INFO:tensorflow:Transforming feature_column _RealValuedColumn(column_name='inputbands', dimension=7, default_value=None, dtype=tf.float32, normalizer=None)<br/>master: WARNING:tensorflow:Please specify metrics using MetricSpec. Using bare functions or (key, fn) tuples is deprecated and support for it will be removed on Oct 1, 2016.<br/>master: WARNING:tensorflow:Please specify metrics using MetricSpec. Using bare functions or (key, fn) tuples is deprecated and support for it will be removed on Oct 1, 2016.<br/>master: INFO:tensorflow:Restored model from /content/training-data-analyst/blogs/landsat-ml/landcover_trained/train<br/>master: INFO:tensorflow:Eval steps [0,100) for training step 1000.<br/>master: INFO:tensorflow:Results after 10 steps (0.003 sec/batch): loss = 0.740265, training/hptuning/metric = 0.73, accuracy = 0.73.<br/>master: INFO:tensorflow:Results after 20 steps (0.001 sec/batch): loss = 0.76891, training/hptuning/metric = 0.731667, accuracy = 0.731667.<br/>master: INFO:tensorflow:Results after 30 steps (0.001 sec/batch): loss = 0.746451, training/hptuning/metric = 0.741111, accuracy = 0.741111.<br/>master: INFO:tensorflow:Results after 40 steps (0.001 sec/batch): loss = 0.713551, training/hptuning/metric = 0.753333, accuracy = 0.753333.<br/>master: INFO:tensorflow:Results after 50 steps (0.001 sec/batch): loss = 0.701148, training/hptuning/metric = 0.76, accuracy = 0.76.<br/>master: INFO:tensorflow:Results after 60 steps (0.001 sec/batch): loss = 0.681787, training/hptuning/metric = 0.766667, accuracy = 0.766667.<br/>master: INFO:tensorflow:Results after 70 steps (0.001 sec/batch): loss = 0.676117, training/hptuning/metric = 0.77, accuracy = 0.77.<br/>master: INFO:tensorflow:Results after 80 steps (0.001 sec/batch): loss = 0.670846, training/hptuning/metric = 0.77375, accuracy = 0.77375.<br/>master: INFO:tensorflow:Results after 90 steps (0.001 sec/batch): loss = 0.669033, training/hptuning/metric = 0.772593, accuracy = 0.772593.<br/>master: INFO:tensorflow:Results after 100 steps (0.001 sec/batch): loss = 0.666091, training/hptuning/metric = 0.774333, accuracy = 0.774333.<br/>master: W tensorflow/core/kernels/queue_base.cc:294] _7_batch/fifo_queue: Skipping cancelled enqueue attempt with queue not closed<br/>master: W tensorflow/core/kernels/queue_base.cc:294] _7_batch/fifo_queue: Skipping cancelled enqueue attempt with queue not closed<br/>master: W tensorflow/core/kernels/queue_base.cc:294] _6_input_producer: Skipping cancelled enqueue attempt with queue not closed<br/>master: INFO:tensorflow:Saving evaluation summary for 1000 step: loss = 0.666091, training/hptuning/metric = 0.774333, accuracy = 0.774333<br/>master: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>Job Finished.</p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%mlalpha train\n",
    "package_uris: /content/training-data-analyst/blogs/landsat-ml/landcover.tgz\n",
    "python_module: trainer.task\n",
    "scale_tier: BASIC\n",
    "region: us-central1\n",
    "args:\n",
    "  train_data_paths: /content/training-data-analyst/blogs/landsat-ml/landcover_preproc/features_train-*\n",
    "  eval_data_paths: /content/training-data-analyst/blogs/landsat-ml/landcover_preproc/features_eval-*\n",
    "  metadata_path: /content/training-data-analyst/blogs/landsat-ml/landcover_preproc/metadata.yaml\n",
    "  output_path: /content/training-data-analyst/blogs/landsat-ml/landcover_trained\n",
    "  max_steps:  2000\n",
    "  batch_size: 10000\n",
    "  layer1_size: 30\n",
    "  layer2_size: 10\n",
    "  learning_rate: 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Train on full dataset on the cloud</h2>\n",
    "\n",
    "Let's preprocess the complete dataset.  These steps will take <b>several hours</b>. I have this code commented out so that I don't run it by mistake when I execute the whole notebook :)\n",
    "\n",
    "Specify your bucket and project as appropriate. Make sure that the bucket you use is a single-region bucket (when you create a bucket, there is an option to specify this). If you already have a bucket and it is not a single-region one, you should create a separate single-region bucket for Cloud ML jobs to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#run_preprocessing(BUCKET='cloud-training-demos-ml', PROJECT='cloud-training-demos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 gs://cloud-training-demos-ml/landcover/preproc/features_eval.tfrecord.gz-temp-2016-11-04_05-23-49/\r\n",
      "                                 gs://cloud-training-demos-ml/landcover/preproc/features_train.tfrecord.gz-temp-2016-11-04_05-23-48/\r\n",
      "                                 gs://cloud-training-demos-ml/landcover/preproc/metadata.yaml-temp-2016-11-04_05-23-47/\r\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls -l gs://cloud-training-demos-ml/landcover/preproc/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tar up the Python package and make it available on Cloud Storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "landcover/\n",
      "landcover/trainer/\n",
      "landcover/trainer/task.py\n",
      "landcover/trainer/util.py\n",
      "landcover/trainer/__init__.py\n",
      "landcover/setup.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CommandException: 1 files/objects could not be removed.\n",
      "Copying file://landcover.tgz [Content-Type=application/x-tar]...\n",
      "/ [0 files][    0.0 B/  4.9 KiB]                                                \r",
      "/ [1 files][  4.9 KiB/  4.9 KiB]                                                \r\n",
      "Operation completed over 1 objects/4.9 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "BUCKET=cloud-training-demos-ml\n",
    "gsutil -m rm -rf gs://$BUCKET/landcover/trained\n",
    "tar cvfz landcover.tgz landcover\n",
    "gsutil cp landcover.tgz gs://$BUCKET/landcover/source/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the same as the local training except:\n",
    "<ol>\n",
    "<li> --cloud parameter to do the training on the Cloud in a distributed way rather on a single machine.\n",
    "<li> all the data paths point to Cloud Storage, where our preprocessing code wrote its output\n",
    "<li> max_steps is much larger.  This is because a step is only one batch.  The entire dataset is 178m points, and since batchsize is 10000, we need\n",
    "17,800 steps for a single epoch (or pass through training data).  So, the 1780000 here is approximately 100 epochs of training.\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%mlalpha train --cloud\n",
    "package_uris: gs://cloud-training-demos-ml/landcover/source/landcover.tgz\n",
    "python_module: trainer.task\n",
    "scale_tier: BASIC\n",
    "region: us-central1\n",
    "args:\n",
    "  train_data_paths: gs://cloud-training-demos-ml/landcover/preproc/features_train-*\n",
    "  eval_data_paths: gs://cloud-training-demos-ml/landcover/preproc/features_eval-*\n",
    "  metadata_path: gs://cloud-training-demos-ml/landcover/preproc/metadata.yaml\n",
    "  output_path: gs://cloud-training-demos-ml/landcover/trained\n",
    "  max_steps:  1780000\n",
    "  batch_size: 10000\n",
    "  layer1_size: 30\n",
    "  layer2_size: 10\n",
    "  learning_rate: 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copyright 2016 Google Inc. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
