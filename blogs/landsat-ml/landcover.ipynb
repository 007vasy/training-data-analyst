{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Downscaling Landcover data using Cloud ML </h1>\n",
    "\n",
    "In this notebook, we train a TensorFlow model to fit Landsat 8 bands to a low-resolution landcover map. Then, we use that model on the high-resolution Landsat data to create a high-resolution landcover map. In essence, we are using TensorFlow to \"statistically downscale\" the landcover data (note that the term \"downscaling\" is counterintuitive -- downscaling an image increases its resolution or upsamples it).\n",
    "\n",
    "<br/>\n",
    "<h3> Set up </h3>\n",
    "\n",
    "As a first step, we install a Python package capable of reading GDAL files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "python-gdal is already the newest version.\n",
      "0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "# Note: after running this cell, you need to Reset Session in Datalab to pick up the new package\n",
    "# You may need to change this to \"!sudo apt-get\" if you get permission problems.\n",
    "!apt-get -y install python-gdal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GDAL library won't be able to read directly from Cloud Storage, so let's download the data to disk. Note that if you started Datalab on a VM without enough space, this might fail.  If you launched Datalab using the codelab instructors, change instance_details.sh to have a disk of at least 20 GB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%bash\n",
    "if [ ! -d input_data ]; then\n",
    "   mkdir input_data\n",
    "   for band in `seq 1 7`; do\n",
    "     gsutil cp gs://mdh-test/landsat-ml/landsat8-b$band.tif input_data\n",
    "   done\n",
    "   gsutil cp gs://mdh-test/landsat-ml/srtm-elevation.tif input_data\n",
    "   gsutil cp gs://mdh-test/landsat-ml/mcd12-labels.tif input_data\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Preprocessing </h3>\n",
    "\n",
    "Preprocessing in Cloud ML is done using Cloud Dataflow.  We'll need to read the Geotiffs and then merge them in such a way that all the data corresponding to a pixel becomes a single TFRecord."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import osgeo.gdal as gdal\n",
    "import struct\n",
    "import numpy as np\n",
    "\n",
    "def read_geotiff(filename):\n",
    "    \"\"\"\n",
    "    return 1-D array of pixel values\n",
    "    \"\"\"\n",
    "    ds = gdal.Open( filename, gdal.GA_ReadOnly )\n",
    "    band = ds.GetRasterBand(1)\n",
    "    ncols = band.XSize\n",
    "    nrows = band.YSize\n",
    "    print \"Reading \", nrows, \"x\", ncols, \" image from \", filename\n",
    "    packformat = 'f' * ncols\n",
    "    result = np.zeros([nrows*ncols], dtype=np.float32)  # 1-D array of pixel values\n",
    "    for line in xrange(0, nrows):\n",
    "      line_data = struct.unpack(packformat, band.ReadRaster(0, line, ncols, 1, ncols, 1, gdal.GDT_Float32))\n",
    "      result[line*ncols:(line+1)*ncols] = line_data\n",
    "    ds = None\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading  16384 x 16384  image from  input_data/landsat8-b1.tif\n",
      "Reading  16384 x 16384  image from  input_data/landsat8-b2.tif\n",
      "Reading  16384 x 16384  image from  input_data/mcd12-labels.tif\n",
      "0.100187 0.081537 1.0\n"
     ]
    }
   ],
   "source": [
    "b1 = read_geotiff('input_data/landsat8-b1.tif')\n",
    "b2 = read_geotiff('input_data/landsat8-b2.tif')\n",
    "lc = read_geotiff('input_data/mcd12-labels.tif')\n",
    "print b1[200], b2[200], lc[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.13659808,   0.13656577,  10.        ], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = np.stack([b1, b2, lc], axis=-1)\n",
    "print all_data[200,:]\n",
    "np.random.shuffle(all_data)\n",
    "print all_data[200,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187904819\n"
     ]
    }
   ],
   "source": [
    "tot_samples = len(all_data)\n",
    "num_train = int(tot_samples * 0.7)\n",
    "print num_train\n",
    "train_data = all_data[:num_train,:]\n",
    "eval_data  = all_data[num_train:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11.0rc0\n",
      "gs://cloud-ml/sdk/cloudml-0.1.6-alpha.dataflow.tar.gz\n"
     ]
    }
   ],
   "source": [
    "import google.cloud.ml as ml\n",
    "import tensorflow as tf\n",
    "print tf.__version__\n",
    "print ml.sdk_location\n",
    "import google.cloud.ml.features as features\n",
    "\n",
    "#import google.cloud.ml as ml\n",
    "#print ml.sdk_location\n",
    "\n",
    "class LandcoverFeatures(object):\n",
    "  columns = ('b1', 'b2', 'landcover')\n",
    "  target = features.target('landcover').discrete()  # classification problem\n",
    "  inputs = [\n",
    "      features.numeric('b1').identity(),\n",
    "      features.numeric('b2').identity(),\n",
    "      #features.numeric('b3').identity(),\n",
    "      #features.numeric('b4').identity(),\n",
    "      #features.numeric('b5').identity(),\n",
    "      #features.numeric('b6').identity(),\n",
    "      #features.numeric('b7').identity(),\n",
    "      #features.numeric('el').identity(),  # elevation\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "import google.cloud.ml as ml\n",
    "import google.cloud.ml.io as io\n",
    "import os\n",
    "\n",
    "# defines\n",
    "feature_set = LandcoverFeatures()\n",
    "OUTPUT_DIR = './preproc'\n",
    "pipeline = beam.Pipeline('DirectPipelineRunner')\n",
    "\n",
    "# preprocessing\n",
    "train = pipeline | beam.Create(train_data)\n",
    "eval = pipeline | beam.Create(eval_data)\n",
    "(metadata, train_features, eval_features) = ((train, eval) |\n",
    "   'Preprocess' >> ml.Preprocess(feature_set))\n",
    "\n",
    "(metadata\n",
    "   | 'SaveMetadata'\n",
    "   >> io.SaveMetadata(os.path.join(OUTPUT_DIR, 'metadata.yaml')))\n",
    "(train_features\n",
    "   | 'WriteTraining'\n",
    "   >> io.SaveFeatures(os.path.join(OUTPUT_DIR, 'features_train')))\n",
    "(eval_features\n",
    "   | 'WriteEval'\n",
    "   >> io.SaveFeatures(os.path.join(OUTPUT_DIR, 'features_eval')))\n",
    "\n",
    "# run pipeline\n",
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
