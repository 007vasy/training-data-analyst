{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Creating high-resolution Landcover data using Machine Learning </h1>\n",
    "\n",
    "In this notebook, we train a TensorFlow model to fit Landsat 8 bands to a low-resolution landcover map. Then, we use that model on the high-resolution Landsat data to create a high-resolution landcover map. In essence, we are using TensorFlow to <a href=\"https://gisclimatechange.ucar.edu/question/63\">statistically downscale</a> the landcover data (note that the term \"downscaling\" is counterintuitive -- downscaling an image increases its resolution or upsamples it).\n",
    "\n",
    "<div id=\"toc\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Preprocessing using Cloud Dataflow </h2>\n",
    "\n",
    "Cloud Dataflow can scale up and simplify preprocessing in Cloud ML.  We'll need to read the Geotiffs and then merge them in such a way that all the data corresponding to a pixel becomes a single TFRecord. We'll also need to scale the pixel values to lie in the range [0,1]. If you do this sort of thing naively, you'll run out of memory or burn through your wallet -- the total size of the images alone is 25 GB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# a Python generator that packs all the training data line-by-line\n",
    "def get_next_line(SMALL_SAMPLE):\n",
    "  '''\n",
    "      return (lineno, linedata, featnames)\n",
    "      where linedata is a 2D array with first dimension being feature# and second dimension column in image \n",
    "  '''  \n",
    "  import osgeo.gdal as gdal\n",
    "  import struct\n",
    "  import os\n",
    "  import subprocess\n",
    "  \n",
    "  # The gdal library can not read from CloudStorage, so this class downloads the data to local VM\n",
    "  class LandsatReader():\n",
    "   def __init__(self, gsfile, destdir='./'):\n",
    "      self.gsfile = gsfile\n",
    "      self.dest = os.path.join(destdir, os.path.basename(self.gsfile))\n",
    "      if os.path.exists(self.dest):\n",
    "        print 'Using already existing {}'.format(self.dest)\n",
    "      else:\n",
    "        print 'Getting {0} to {1} '.format(self.gsfile, self.dest)\n",
    "        ret = subprocess.check_call(['gsutil', 'cp', self.gsfile, self.dest])\n",
    "      self.dataset = gdal.Open( self.dest, gdal.GA_ReadOnly )\n",
    "   def __exit__(self, exc_type=None, exc_val=None, exc_tb=None):\n",
    "      os.remove( self.dest ) # cleanup  \n",
    "   def ds(self):\n",
    "      return self.dataset\n",
    "\n",
    "  # open all the necessary files\n",
    "  input_dir = 'gs://mdh-test/landsat-ml/'\n",
    "  featnames = ['b{}'.format(band) for band in xrange(1,8)] # 8\n",
    "  filenames = [os.path.join(input_dir, 'landsat8-{}.tif'.format(band)) for band in featnames]\n",
    "  filenames.append(os.path.join(input_dir, 'srtm-elevation.tif')); featnames.append('elev')\n",
    "  filenames.append(os.path.join(input_dir, 'mcd12-labels.tif')); featnames.append('landcover')\n",
    "  readers = [LandsatReader(filename) for filename in filenames]\n",
    "  bands = [reader.ds().GetRasterBand(1) for reader in readers] \n",
    "  print \"Opened \", filenames\n",
    "      \n",
    "  # read one row of each the images and yield them\n",
    "  ncols = bands[0].XSize\n",
    "  nrows = bands[0].YSize\n",
    "  if SMALL_SAMPLE:\n",
    "    nrows_to_read = 200\n",
    "    ncols_to_read = 1000\n",
    "  else:\n",
    "    nrows_to_read = nrows\n",
    "    ncols_to_read = ncols\n",
    "  print \"Reading \", nrows_to_read, \"x\", ncols_to_read, \" from \", nrows, 'x', ncols, ' images corresponding to ', featnames\n",
    "  packformat = 'f' * ncols\n",
    "  for line in xrange(0, nrows_to_read):\n",
    "        line_data = [struct.unpack(packformat, band.ReadRaster(0, line, ncols, 1, ncols, 1, gdal.GDT_Float32)) for band in bands]\n",
    "        yield (line, line_data, featnames, ncols_to_read)\n",
    "      \n",
    "def get_features_from_line(args):\n",
    "  '''\n",
    "      return (1, dict)  or (0, dict)\n",
    "      where the first number is 1 or 0 depending on whether this row belongs to training (1)\n",
    "      or eval (0) partition.\n",
    "      dict is the set of features formed from pixels from all the bands\n",
    "  ''' \n",
    "  (line, line_data, featnames, ncols_to_read) = args\n",
    "  if line_data:\n",
    "    for col in xrange(0, ncols_to_read):\n",
    "          featdict = {'rowcol': '{},{}'.format(line,col)}\n",
    "          for f in xrange(0, len(featnames)):\n",
    "            featdict[featnames[f]] = line_data[f][col]\n",
    "          featdict['landcover'] = '{}'.format(int(featdict['landcover']+0.5))\n",
    "          yield ( 0 if (line+col)%3==0 else 1, featdict )    # 1/3 are eval\n",
    "\n",
    "def get_partition(group_and_featdict, nparts):\n",
    "  (is_train, featdict) = group_and_featdict\n",
    "  return is_train # 0 or 1\n",
    "\n",
    "def get_featdict(group_and_featdict):\n",
    "  (is_train, featdict) = group_and_featdict\n",
    "  return featdict\n",
    "\n",
    "def run_preprocessing(BUCKET=None, PROJECT=None):\n",
    "  import os\n",
    "  import numpy as np\n",
    "  import apache_beam as beam\n",
    "  import google.cloud.ml as ml\n",
    "  import google.cloud.ml.io as io\n",
    "  import google.cloud.ml.features as features\n",
    "\n",
    "  # small sample locally; full dataset on cloud\n",
    "  if BUCKET is None or PROJECT is None:\n",
    "    SMALL_SAMPLE = True\n",
    "    OUTPUT_DIR = './landcover_preproc'\n",
    "    RUNNER = 'DirectPipelineRunner'\n",
    "  else:\n",
    "    SMALL_SAMPLE = False\n",
    "    OUTPUT_DIR = 'gs://{0}/landcover/preproc'.format(BUCKET)\n",
    "    RUNNER = 'DataflowPipelineRunner'\n",
    "  #\n",
    "  \n",
    "  pipeline = beam.Pipeline(argv=['--project', PROJECT,\n",
    "                               '--runner', RUNNER,\n",
    "                               '--job_name', 'landcover',\n",
    "                               '--extra_package', ml.sdk_location,\n",
    "                               '--max_num_workers', '10',\n",
    "                               '--no_save_main_session', 'True',  # to prevent pickling and uploading Datalab itself!\n",
    "                               '--setup_file', './preproc/setup.py',  # for gdal installation on the cloud -- see CUSTOM_COMMANDS in setup.py\n",
    "                               '--staging_location', 'gs://{0}/landcover/staging'.format(BUCKET),\n",
    "                               '--temp_location', 'gs://{0}/landcover/temp'.format(BUCKET)])\n",
    "        \n",
    "  print ml.sdk_location\n",
    "  (evalg, traing) = (pipeline \n",
    "     | beam.Create([SMALL_SAMPLE]) # make the generator function like a source\n",
    "     | beam.FlatMap(get_next_line)\n",
    "     | beam.FlatMap(get_features_from_line) # (is_train, featdict)\n",
    "     | beam.Partition(get_partition, 2)\n",
    "  )  # eval, train both contain (is_train, featdict)\n",
    "  eval = evalg | 'eval_features' >> beam.Map(get_featdict)\n",
    "  train = traing | 'train_features' >> beam.Map(get_featdict)\n",
    "  \n",
    "  class LandcoverFeatures(object):\n",
    "    key = features.key('rowcol')\n",
    "    landcover = features.target('landcover').discrete()  # classification problem\n",
    "    inputbands = [\n",
    "      features.numeric('b1').scale(),\n",
    "      features.numeric('b2').scale(),\n",
    "      features.numeric('b3').scale(),\n",
    "      features.numeric('b4').scale(),\n",
    "      features.numeric('b5').scale(),\n",
    "      features.numeric('b6').scale(),\n",
    "      features.numeric('b7').scale(),\n",
    "      #features.numeric('el').discretize(buckets=[1,5001,50], sparse=True),  # elevation\n",
    "    ]\n",
    "  feature_set = LandcoverFeatures()\n",
    "  (metadata, train_features, eval_features) = ((train, eval) |\n",
    "   'Preprocess' >> ml.Preprocess(feature_set))\n",
    "  (metadata\n",
    "     | 'SaveMetadata'\n",
    "     >> io.SaveMetadata(os.path.join(OUTPUT_DIR, 'metadata.yaml')))\n",
    "  (train_features\n",
    "     | 'WriteTraining'\n",
    "     >> io.SaveFeatures(os.path.join(OUTPUT_DIR, 'features_train')))\n",
    "  (eval_features\n",
    "     | 'WriteEval'\n",
    "     >> io.SaveFeatures(os.path.join(OUTPUT_DIR, 'features_eval')))\n",
    "  pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Create ML model using TensorFlow </h2>\n",
    "\n",
    "I cheated here. I simply took the <a href=\"https://github.com/GoogleCloudPlatform/cloudml-samples/tree/master/iris\">Cloud ML sample for Iris classification</a> and copied it into my repo.  The only change I had to make was to three fields, changing:\n",
    "<pre>\n",
    "KEY_FEATURE_COLUMN = 'key'\n",
    "TARGET_FEATURE_COLUMN = 'species'\n",
    "REAL_VALUED_FEATURE_COLUMNS = 'measurements'\n",
    "</pre>\n",
    "to\n",
    "<pre>\n",
    "KEY_FEATURE_COLUMN = 'key'\n",
    "TARGET_FEATURE_COLUMN = 'landcover'\n",
    "REAL_VALUED_FEATURE_COLUMNS = 'inputbands'\n",
    "</pre>\n",
    "Essentially, my new values match what I had in the class LandcoverFeatures during preprocessing (see above).  This is needed because that's what now encoded in the tfrecord files the preprocessing step wrote out.\n",
    "\n",
    "The model itself is a neural network with 2 hidden layers. The Iris sample uses the tf.learn API. It is a classification network, and the sample does all the saving, exporting, distribution, etc. All my inputs are like the Iris sample in that they are all real-valued columns. Like in the Iris example, the target takes only one value -- a landcover that is brushland can not also be forest. So, I'm relatively safe in reusing the Iris model as-is.  Of course, I should probably do some feature engineering, by calculating normalized differences, for example. But for now, the Iris sample will suffice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "landcover:\r\n",
      "total 8\r\n",
      "-rw-r--r-- 1 root root  746 Nov  3 18:28 setup.py\r\n",
      "drwxr-xr-x 2 root root 4096 Nov  3 23:07 trainer\r\n",
      "\r\n",
      "landcover/trainer:\r\n",
      "total 24\r\n",
      "-rw-r--r-- 1 root root  677 Nov  3 21:54 __init__.py\r\n",
      "-rw-r--r-- 1 root root 9176 Nov  3 23:07 task.py\r\n",
      "-rw-r--r-- 1 root root 5553 Nov  3 22:51 util.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lR landcover"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Train model locally using Cloud ML </h2>\n",
    "\n",
    "Let's train the model locally on a subset of the data to ensure that we get things right. Then, we can train on the cloud with all of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://cloud-ml/sdk/cloudml-0.1.6-alpha.dataflow.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Direct usage of TextFileSink is deprecated. Please use 'textio.WriteToText()' instead of directly instantiating a TextFileSink object.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using already existing ./landsat8-b1.tif\n",
      "Using already existing ./landsat8-b2.tif\n",
      "Using already existing ./landsat8-b3.tif\n",
      "Using already existing ./landsat8-b4.tif\n",
      "Using already existing ./landsat8-b5.tif\n",
      "Using already existing ./landsat8-b6.tif\n",
      "Using already existing ./landsat8-b7.tif\n",
      "Using already existing ./srtm-elevation.tif\n",
      "Using already existing ./mcd12-labels.tif\n",
      "Opened  ['gs://mdh-test/landsat-ml/landsat8-b1.tif', 'gs://mdh-test/landsat-ml/landsat8-b2.tif', 'gs://mdh-test/landsat-ml/landsat8-b3.tif', 'gs://mdh-test/landsat-ml/landsat8-b4.tif', 'gs://mdh-test/landsat-ml/landsat8-b5.tif', 'gs://mdh-test/landsat-ml/landsat8-b6.tif', 'gs://mdh-test/landsat-ml/landsat8-b7.tif', 'gs://mdh-test/landsat-ml/srtm-elevation.tif', 'gs://mdh-test/landsat-ml/mcd12-labels.tif']\n",
      "Reading  200 x 1000  from  16384 x 16384  images corresponding to  ['b1', 'b2', 'b3', 'b4', 'b5', 'b6', 'b7', 'elev', 'landcover']\n"
     ]
    }
   ],
   "source": [
    "# process a small sample (200k points) by running the preprocessing locally\n",
    "# if your Datalab instance can't handle this, reduce the sample size by changing the preprocessing code\n",
    "# (look for nrows_read and change it from 200 to perhaps 20)\n",
    "# alternately, if you followed the codelab instructions to launch Datalab on a GCE, change the machine\n",
    "# type in instance_details.sh to n1-highmem-2   (should take about 5 minutes on n1-highmem-2)\n",
    "import shutil\n",
    "shutil.rmtree('landcover_preproc', ignore_errors=True)\n",
    "run_preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 7004\r\n",
      "-rw-r--r-- 1 root root 2422582 Nov  4 17:00 features_eval-00000-of-00001.tfrecord.gz\r\n",
      "-rw-r--r-- 1 root root 4740616 Nov  4 17:00 features_train-00000-of-00001.tfrecord.gz\r\n",
      "-rw-r--r-- 1 root root    2086 Nov  4 16:59 metadata.yaml\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l /content/training-data-analyst/blogs/landsat-ml/landcover_preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "landcover/\n",
      "landcover/trainer/\n",
      "landcover/trainer/task.py\n",
      "landcover/trainer/util.py\n",
      "landcover/trainer/__init__.py\n",
      "landcover/setup.py\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "rm -rf /content/training-data-analyst/blogs/landsat-ml/landcover_trained\n",
    "tar cvfz landcover.tgz landcover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>Job Running...</p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/_nocachecontent/master\" target=\"_blank\">master log</a>&nbsp;&nbsp;"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "master: INFO:tensorflow:Transforming feature_column _RealValuedColumn(column_name='inputbands', dimension=7, default_value=None, dtype=tf.float32, normalizer=None)<br/>master: WARNING:tensorflow:Please specify metrics using MetricSpec. Using bare functions or (key, fn) tuples is deprecated and support for it will be removed on Oct 1, 2016.<br/>master: WARNING:tensorflow:Please specify metrics using MetricSpec. Using bare functions or (key, fn) tuples is deprecated and support for it will be removed on Oct 1, 2016.<br/>master: INFO:tensorflow:Restored model from /content/training-data-analyst/blogs/landsat-ml/landcover_trained/train<br/>master: INFO:tensorflow:Eval steps [0,100) for training step 2000.<br/>master: INFO:tensorflow:Results after 10 steps (0.003 sec/batch): loss = 0.869211, training/hptuning/metric = 0.713333, accuracy = 0.713333.<br/>master: INFO:tensorflow:Results after 20 steps (0.001 sec/batch): loss = 0.949071, training/hptuning/metric = 0.67, accuracy = 0.67.<br/>master: INFO:tensorflow:Results after 30 steps (0.001 sec/batch): loss = 0.945961, training/hptuning/metric = 0.673333, accuracy = 0.673333.<br/>master: INFO:tensorflow:Results after 40 steps (0.002 sec/batch): loss = 0.910532, training/hptuning/metric = 0.679167, accuracy = 0.679167.<br/>master: INFO:tensorflow:Results after 50 steps (0.001 sec/batch): loss = 0.916385, training/hptuning/metric = 0.676, accuracy = 0.676.<br/>master: INFO:tensorflow:Results after 60 steps (0.001 sec/batch): loss = 0.910499, training/hptuning/metric = 0.68, accuracy = 0.68.<br/>master: INFO:tensorflow:Results after 70 steps (0.001 sec/batch): loss = 0.917, training/hptuning/metric = 0.675714, accuracy = 0.675714.<br/>master: INFO:tensorflow:Results after 80 steps (0.001 sec/batch): loss = 0.914597, training/hptuning/metric = 0.674167, accuracy = 0.674167.<br/>master: INFO:tensorflow:Results after 90 steps (0.001 sec/batch): loss = 0.920474, training/hptuning/metric = 0.671852, accuracy = 0.671852.<br/>master: INFO:tensorflow:Results after 100 steps (0.001 sec/batch): loss = 0.922165, training/hptuning/metric = 0.672, accuracy = 0.672.<br/>master: W tensorflow/core/kernels/queue_base.cc:294] _10_batch/fifo_queue: Skipping cancelled enqueue attempt with queue not closed<br/>master: W tensorflow/core/kernels/queue_base.cc:294] _10_batch/fifo_queue: Skipping cancelled enqueue attempt with queue not closed<br/>master: W tensorflow/core/kernels/queue_base.cc:294] _9_input_producer: Skipping cancelled enqueue attempt with queue not closed<br/>master: INFO:tensorflow:Saving evaluation summary for 2000 step: loss = 0.922165, training/hptuning/metric = 0.672, accuracy = 0.672<br/>master: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>Job Finished.</p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%mlalpha train\n",
    "package_uris: /content/training-data-analyst/blogs/landsat-ml/landcover.tgz\n",
    "python_module: trainer.task\n",
    "scale_tier: BASIC\n",
    "region: us-central1\n",
    "args:\n",
    "  train_data_paths: /content/training-data-analyst/blogs/landsat-ml/landcover_preproc/features_train-*\n",
    "  eval_data_paths: /content/training-data-analyst/blogs/landsat-ml/landcover_preproc/features_eval-*\n",
    "  metadata_path: /content/training-data-analyst/blogs/landsat-ml/landcover_preproc/metadata.yaml\n",
    "  output_path: /content/training-data-analyst/blogs/landsat-ml/landcover_trained\n",
    "  max_steps:  2000\n",
    "  batch_size: 10000\n",
    "  layer1_size: 30\n",
    "  layer2_size: 10\n",
    "  learning_rate: 0.01\n",
    "  min_eval_frequency: 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Deploy locally trained model </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing gs://cloud-training-demos-ml/landcover/trained_local/checkpoint#1478284988586060...\n",
      "Removing gs://cloud-training-demos-ml/landcover/trained_local/export#1478284988554092...\n",
      "Removing gs://cloud-training-demos-ml/landcover/trained_local/export.meta#1478284988719234...\n",
      "Removing gs://cloud-training-demos-ml/landcover/trained_local/metadata.yaml#1478284988931989...\n",
      "/ [1/4 objects]  25% Done                                                       \r",
      "/ [2/4 objects]  50% Done                                                       \r",
      "/ [3/4 objects]  75% Done                                                       \r",
      "/ [4/4 objects] 100% Done                                                       \r\n",
      "Operation completed over 4 objects.                                              \n",
      "Copying file://landcover_trained/model/export.meta [Content-Type=application/octet-stream]...\n",
      "Copying file://landcover_trained/model/metadata.yaml [Content-Type=application/octet-stream]...\n",
      "Copying file://landcover_trained/model/checkpoint [Content-Type=application/octet-stream]...\n",
      "Copying file://landcover_trained/model/export [Content-Type=application/octet-stream]...\n",
      "/ [0/4 files][    0.0 B/ 40.5 KiB]   0% Done                                    \r",
      "/ [0/4 files][    0.0 B/ 40.5 KiB]   0% Done                                    \r",
      "/ [0/4 files][    0.0 B/ 40.5 KiB]   0% Done                                    \r",
      "/ [0/4 files][    0.0 B/ 40.5 KiB]   0% Done                                    \r",
      "/ [1/4 files][ 40.5 KiB/ 40.5 KiB]  99% Done                                    \r",
      "/ [2/4 files][ 40.5 KiB/ 40.5 KiB]  99% Done                                    \r",
      "/ [3/4 files][ 40.5 KiB/ 40.5 KiB]  99% Done                                    \r",
      "/ [4/4 files][ 40.5 KiB/ 40.5 KiB] 100% Done                                    \r\n",
      "Operation completed over 4 objects/40.5 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "GCSPATH=gs://cloud-training-demos-ml/landcover/trained_local\n",
    "gsutil -m rm -rf $GCSPATH\n",
    "gsutil -m cp -r landcover_trained/model $GCSPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<HttpError 409 when requesting https://ml.googleapis.com/v1beta1/projects/cloud-training-demos/models/landcover/versions?alt=json returned \"Field: version.name Error: A version with the same name already exists.\">\n"
     ]
    }
   ],
   "source": [
    "%mlalpha deploy --name landcover.v0 --path gs://cloud-training-demos-ml/landcover/trained_local --project cloud-training-demos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Predict with deployed model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_landcover(featdict):\n",
    "  from googleapiclient import discovery\n",
    "  from oauth2client.client import GoogleCredentials\n",
    "  import json\n",
    "\n",
    "  import google.cloud.ml.features as features\n",
    "  from google.cloud.ml import session_bundle\n",
    "\n",
    "  credentials = GoogleCredentials.get_application_default()\n",
    "  api = discovery.build('ml', 'v1beta1', credentials=credentials,\n",
    "            discoveryServiceUrl='https://storage.googleapis.com/cloud-ml/discovery/ml_v1beta1_discovery.json')\n",
    "\n",
    "  request_data = {'instances':\n",
    "    [\n",
    "      {\n",
    "        'examples': featdict\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "\n",
    "  print json.dumps(request_data)\n",
    "  parent = 'projects/%s/models/%s/versions/%s' % ('cloud-training-demos', 'landcover', 'v0')\n",
    "  response = api.projects().predict(body=request_data, name=parent).execute()\n",
    "  print \"response={0}\".format(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'b4': 0.051566123962402344, 'b5': 0.1666821539402008, 'b6': 0.11377514898777008, 'b7': 0.0633927434682846, 'rowcol': '0,0', 'b1': 0.09934771060943604, 'elev': 1623.0, 'b3': 0.06303835660219193, 'b2': 0.07937479019165039}\n",
      "{\"instances\": [{\"examples\": {\"b4\": 0.051566123962402344, \"b5\": 0.1666821539402008, \"b6\": 0.11377514898777008, \"b7\": 0.0633927434682846, \"rowcol\": \"0,0\", \"b1\": 0.09934771060943604, \"elev\": 1623.0, \"b3\": 0.06303835660219193, \"b2\": 0.07937479019165039}}]}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No JSON object could be decoded",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-888782e85c7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mtest_feat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'landcover'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mtest_feat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpredict_landcover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_feat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-35-fbb76438bfd2>\u001b[0m in \u001b[0;36mpredict_landcover\u001b[0;34m(featdict)\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0;32mprint\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0mparent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'projects/%s/models/%s/versions/%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'cloud-training-demos'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'landcover'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'v0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m   \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprojects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m   \u001b[0;32mprint\u001b[0m \u001b[0;34m\"response={0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/oauth2client/util.pyc\u001b[0m in \u001b[0;36mpositional_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mpositional_parameters_enforcement\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPOSITIONAL_WARNING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpositional_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/googleapiclient/http.pyc\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, http, num_retries)\u001b[0m\n\u001b[1;32m    831\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mHttpError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/googleapiclient/model.pyc\u001b[0m in \u001b[0;36mresponse\u001b[0;34m(self, resp, content)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;31m# to all the other success states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_content_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m       \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Content from bad request was: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/googleapiclient/model.pyc\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(self, content)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_wrapper\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'data'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m       \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/json/__init__.pyc\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 338\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/json/decoder.pyc\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \"\"\"\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/json/decoder.pyc\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    382\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No JSON object could be decoded\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No JSON object could be decoded"
     ]
    }
   ],
   "source": [
    "test_feat = {'elev': 1623.0, 'b4': 0.051566123962402344, 'b5': 0.1666821539402008, 'b6': 0.11377514898777008, 'b7': 0.0633927434682846, 'rowcol': '0,0', 'b1': 0.09934771060943604, 'b2': 0.07937479019165039, 'b3': 0.06303835660219193, 'landcover': '1'}\n",
    "del test_feat['landcover']\n",
    "print test_feat\n",
    "predict_landcover(test_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using already existing ./landsat8-b1.tif\n",
      "Using already existing ./landsat8-b2.tif\n",
      "Using already existing ./landsat8-b3.tif\n",
      "Using already existing ./landsat8-b4.tif\n",
      "Using already existing ./landsat8-b5.tif\n",
      "Using already existing ./landsat8-b6.tif\n",
      "Using already existing ./landsat8-b7.tif\n",
      "Using already existing ./srtm-elevation.tif\n",
      "Using already existing ./mcd12-labels.tif\n",
      "Opened  ['gs://mdh-test/landsat-ml/landsat8-b1.tif', 'gs://mdh-test/landsat-ml/landsat8-b2.tif', 'gs://mdh-test/landsat-ml/landsat8-b3.tif', 'gs://mdh-test/landsat-ml/landsat8-b4.tif', 'gs://mdh-test/landsat-ml/landsat8-b5.tif', 'gs://mdh-test/landsat-ml/landsat8-b6.tif', 'gs://mdh-test/landsat-ml/landsat8-b7.tif', 'gs://mdh-test/landsat-ml/srtm-elevation.tif', 'gs://mdh-test/landsat-ml/mcd12-labels.tif']\n",
      "Reading  200 x 1000  from  16384 x 16384  images corresponding to  ['b1', 'b2', 'b3', 'b4', 'b5', 'b6', 'b7', 'elev', 'landcover']\n",
      "{'elev': 1623.0, 'b4': 0.051566123962402344, 'b5': 0.1666821539402008, 'b6': 0.11377514898777008, 'b7': 0.0633927434682846, 'rowcol': '0,0', 'b1': 0.09934771060943604, 'b2': 0.07937479019165039, 'b3': 0.06303835660219193, 'landcover': '1'}\n",
      "{'elev': 1620.0, 'b4': 0.05217121168971062, 'b5': 0.1811048686504364, 'b6': 0.10504324734210968, 'b7': 0.06008840724825859, 'rowcol': '0,1', 'b1': 0.09787668287754059, 'b2': 0.07955973595380783, 'b3': 0.0637759119272232, 'landcover': '1'}\n",
      "{'elev': 1614.0, 'b4': 0.05213399603962898, 'b5': 0.19318675994873047, 'b6': 0.1052640825510025, 'b7': 0.059842124581336975, 'rowcol': '0,2', 'b1': 0.09884268045425415, 'b2': 0.0807022899389267, 'b3': 0.06296388804912567, 'landcover': '1'}\n"
     ]
    }
   ],
   "source": [
    "nproc = 0\n",
    "for lineargs in get_next_line(SMALL_SAMPLE=True):\n",
    "    for (_, featdict) in get_features_from_line(lineargs):\n",
    "      print featdict\n",
    "      nproc = nproc + 1\n",
    "      if nproc > 2: # just the first three\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Train on full dataset on the cloud</h2>\n",
    "\n",
    "Let's preprocess the complete dataset.  <b>These steps will take several hours and have billing implications</b>.\n",
    "\n",
    "Specify your bucket and project as appropriate. Make sure that the bucket you use is a single-region bucket (when you create a bucket, there is an option to specify this). If you already have a bucket and it is not a single-region one, you should create a separate single-region bucket for Cloud ML jobs to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#run_preprocessing(BUCKET='cloud-training-demos-ml', PROJECT='cloud-training-demos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Updates are available for some Cloud SDK components.  To install them,\n",
      "please run:\n",
      "  $ gcloud components update\n",
      "\n",
      "  11911414  2016-11-04T18:12:29Z  gs://cloud-training-demos-ml/landcover/preproc/features_eval-00000-of-00017.tfrecord.gz\n",
      "   1399595  2016-11-04T18:12:29Z  gs://cloud-training-demos-ml/landcover/preproc/features_eval-00001-of-00017.tfrecord.gz\n",
      "    722332  2016-11-04T18:12:29Z  gs://cloud-training-demos-ml/landcover/preproc/features_eval-00002-of-00017.tfrecord.gz\n",
      "  61908282  2016-11-04T18:12:29Z  gs://cloud-training-demos-ml/landcover/preproc/features_eval-00003-of-00017.tfrecord.gz\n",
      "  62458050  2016-11-04T18:12:29Z  gs://cloud-training-demos-ml/landcover/preproc/features_eval-00004-of-00017.tfrecord.gz\n",
      " 233743299  2016-11-04T18:12:29Z  gs://cloud-training-demos-ml/landcover/preproc/features_eval-00005-of-00017.tfrecord.gz\n",
      "   5783557  2016-11-04T18:12:29Z  gs://cloud-training-demos-ml/landcover/preproc/features_eval-00006-of-00017.tfrecord.gz\n",
      " 130264412  2016-11-04T18:12:29Z  gs://cloud-training-demos-ml/landcover/preproc/features_eval-00007-of-00017.tfrecord.gz\n",
      "  23244901  2016-11-04T18:12:29Z  gs://cloud-training-demos-ml/landcover/preproc/features_eval-00008-of-00017.tfrecord.gz\n",
      "1065181613  2016-11-04T18:12:29Z  gs://cloud-training-demos-ml/landcover/preproc/features_eval-00009-of-00017.tfrecord.gz\n",
      " 277395943  2016-11-04T18:12:29Z  gs://cloud-training-demos-ml/landcover/preproc/features_eval-00010-of-00017.tfrecord.gz\n",
      "  28719629  2016-11-04T18:12:29Z  gs://cloud-training-demos-ml/landcover/preproc/features_eval-00011-of-00017.tfrecord.gz\n",
      "1050966190  2016-11-04T18:12:29Z  gs://cloud-training-demos-ml/landcover/preproc/features_eval-00012-of-00017.tfrecord.gz\n",
      "  78715409  2016-11-04T18:12:29Z  gs://cloud-training-demos-ml/landcover/preproc/features_eval-00013-of-00017.tfrecord.gz\n",
      " 130639900  2016-11-04T18:12:29Z  gs://cloud-training-demos-ml/landcover/preproc/features_eval-00014-of-00017.tfrecord.gz\n",
      "    310832  2016-11-04T18:12:29Z  gs://cloud-training-demos-ml/landcover/preproc/features_eval-00015-of-00017.tfrecord.gz\n",
      "   2787529  2016-11-04T18:12:29Z  gs://cloud-training-demos-ml/landcover/preproc/features_eval-00016-of-00017.tfrecord.gz\n",
      " 443549311  2016-11-04T18:12:59Z  gs://cloud-training-demos-ml/landcover/preproc/features_train-00000-of-00024.tfrecord.gz\n",
      "   1192011  2016-11-04T18:12:59Z  gs://cloud-training-demos-ml/landcover/preproc/features_train-00001-of-00024.tfrecord.gz\n",
      "  35677789  2016-11-04T18:12:59Z  gs://cloud-training-demos-ml/landcover/preproc/features_train-00002-of-00024.tfrecord.gz\n",
      "1038657615  2016-11-04T18:12:59Z  gs://cloud-training-demos-ml/landcover/preproc/features_train-00003-of-00024.tfrecord.gz\n",
      " 199716840  2016-11-04T18:12:59Z  gs://cloud-training-demos-ml/landcover/preproc/features_train-00004-of-00024.tfrecord.gz\n",
      "  45670895  2016-11-04T18:12:59Z  gs://cloud-training-demos-ml/landcover/preproc/features_train-00005-of-00024.tfrecord.gz\n",
      "   4878803  2016-11-04T18:12:59Z  gs://cloud-training-demos-ml/landcover/preproc/features_train-00006-of-00024.tfrecord.gz\n",
      "  16880155  2016-11-04T18:12:59Z  gs://cloud-training-demos-ml/landcover/preproc/features_train-00007-of-00024.tfrecord.gz\n",
      " 295734304  2016-11-04T18:12:59Z  gs://cloud-training-demos-ml/landcover/preproc/features_train-00008-of-00024.tfrecord.gz\n",
      "   2526618  2016-11-04T18:12:59Z  gs://cloud-training-demos-ml/landcover/preproc/features_train-00009-of-00024.tfrecord.gz\n",
      "1046941812  2016-11-04T18:12:59Z  gs://cloud-training-demos-ml/landcover/preproc/features_train-00010-of-00024.tfrecord.gz\n",
      "   1436843  2016-11-04T18:12:59Z  gs://cloud-training-demos-ml/landcover/preproc/features_train-00011-of-00024.tfrecord.gz\n",
      "  25896955  2016-11-04T18:12:59Z  gs://cloud-training-demos-ml/landcover/preproc/features_train-00012-of-00024.tfrecord.gz\n",
      " 199163307  2016-11-04T18:12:59Z  gs://cloud-training-demos-ml/landcover/preproc/features_train-00013-of-00024.tfrecord.gz\n",
      "1053759092  2016-11-04T18:12:59Z  gs://cloud-training-demos-ml/landcover/preproc/features_train-00014-of-00024.tfrecord.gz\n",
      "  22568405  2016-11-04T18:12:59Z  gs://cloud-training-demos-ml/landcover/preproc/features_train-00015-of-00024.tfrecord.gz\n",
      "   2890711  2016-11-04T18:12:59Z  gs://cloud-training-demos-ml/landcover/preproc/features_train-00016-of-00024.tfrecord.gz\n",
      " 481782889  2016-11-04T18:12:59Z  gs://cloud-training-demos-ml/landcover/preproc/features_train-00017-of-00024.tfrecord.gz\n",
      "  39446244  2016-11-04T18:12:59Z  gs://cloud-training-demos-ml/landcover/preproc/features_train-00018-of-00024.tfrecord.gz\n",
      " 107611947  2016-11-04T18:12:59Z  gs://cloud-training-demos-ml/landcover/preproc/features_train-00019-of-00024.tfrecord.gz\n",
      " 154284477  2016-11-04T18:12:59Z  gs://cloud-training-demos-ml/landcover/preproc/features_train-00020-of-00024.tfrecord.gz\n",
      "    747465  2016-11-04T18:12:59Z  gs://cloud-training-demos-ml/landcover/preproc/features_train-00021-of-00024.tfrecord.gz\n",
      "1035094056  2016-11-04T18:12:59Z  gs://cloud-training-demos-ml/landcover/preproc/features_train-00022-of-00024.tfrecord.gz\n",
      "    790420  2016-11-04T18:12:59Z  gs://cloud-training-demos-ml/landcover/preproc/features_train-00023-of-00024.tfrecord.gz\n",
      "      2243  2016-11-04T16:57:07Z  gs://cloud-training-demos-ml/landcover/preproc/metadata.yaml\n",
      "TOTAL: 42 objects, 9423054094 bytes (8.78 GiB)\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls -l gs://cloud-training-demos-ml/landcover/preproc/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tar up the Python package and make it available on Cloud Storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "landcover/\n",
      "landcover/trainer/\n",
      "landcover/trainer/task.py\n",
      "landcover/trainer/util.py\n",
      "landcover/trainer/__init__.py\n",
      "landcover/setup.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CommandException: 1 files/objects could not be removed.\n",
      "Copying file://landcover.tgz [Content-Type=application/x-tar]...\n",
      "/ [0 files][    0.0 B/  5.0 KiB]                                                \r",
      "/ [1 files][  5.0 KiB/  5.0 KiB]                                                \r\n",
      "Operation completed over 1 objects/5.0 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "BUCKET=cloud-training-demos-ml\n",
    "gsutil -m rm -rf gs://$BUCKET/landcover/trained\n",
    "tar cvfz landcover.tgz landcover\n",
    "gsutil cp landcover.tgz gs://$BUCKET/landcover/source/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the same as the local training except:\n",
    "<ol>\n",
    "<li> --cloud parameter to do the training on the Cloud in a distributed way rather on a single machine.\n",
    "<li> all the data paths point to Cloud Storage, where our preprocessing code wrote its output\n",
    "<li> max_steps is much larger.  This is because a step is only one batch.  The entire dataset is 178m points, and since batchsize is 10000, we need\n",
    "17,800 steps for a single epoch (or pass through training data).  So, the 1780000 here is approximately 100 epochs of training.\n",
    "<li> The evaluation frequency has been upped to 17,800 for the same reason (so that we evaluate approximately once every epoch)\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%mlalpha train --cloud\n",
    "package_uris: gs://cloud-training-demos-ml/landcover/source/landcover.tgz\n",
    "python_module: trainer.task\n",
    "scale_tier: BASIC\n",
    "region: us-central1\n",
    "args:\n",
    "  train_data_paths: gs://cloud-training-demos-ml/landcover/preproc/features_train-*\n",
    "  eval_data_paths: gs://cloud-training-demos-ml/landcover/preproc/features_eval-*\n",
    "  metadata_path: gs://cloud-training-demos-ml/landcover/preproc/metadata.yaml\n",
    "  output_path: gs://cloud-training-demos-ml/landcover/trained\n",
    "  max_steps:  1780000\n",
    "  batch_size: 10000\n",
    "  layer1_size: 30\n",
    "  layer2_size: 10\n",
    "  learning_rate: 0.01\n",
    "  min_eval_frequency: 17800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copyright 2016 Google Inc. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
