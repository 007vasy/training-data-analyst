{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Downscaling Landcover data using Cloud ML </h1>\n",
    "\n",
    "In this notebook, we train a TensorFlow model to fit Landsat 8 bands to a low-resolution landcover map. Then, we use that model on the high-resolution Landsat data to create a high-resolution landcover map. In essence, we are using TensorFlow to \"statistically downscale\" the landcover data (note that the term \"downscaling\" is counterintuitive -- downscaling an image increases its resolution or upsamples it).\n",
    "\n",
    "<br/>\n",
    "<h3> Set up </h3>\n",
    "\n",
    "As a first step, we install a Python package capable of reading GDAL files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "python-gdal is already the newest version.\n",
      "0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "# Note: after running this cell, you need to Reset Session in Datalab to pick up the new package\n",
    "# You may need to change this to \"!sudo apt-get\" if you get permission problems.\n",
    "!apt-get -y install python-gdal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GDAL library won't be able to read directly from Cloud Storage, so let's download the data to disk. If this fails because of space problems, relaunch Datalab after changing instance_details.sh to have a disk of at least 20 GB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%bash\n",
    "if [ ! -d input_data ]; then\n",
    "   mkdir input_data\n",
    "   for band in `seq 1 7`; do\n",
    "     gsutil cp gs://mdh-test/landsat-ml/landsat8-b$band.tif input_data\n",
    "   done\n",
    "   gsutil cp gs://mdh-test/landsat-ml/srtm-elevation.tif input_data\n",
    "   gsutil cp gs://mdh-test/landsat-ml/mcd12-labels.tif input_data\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Preprocessing </h3>\n",
    "\n",
    "Preprocessing in Cloud ML is done using Cloud Dataflow.  We'll need to read the Geotiffs and then merge them in such a way that all the data corresponding to a pixel becomes a single TFRecord."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11.0rc0\n",
      "gs://cloud-ml/sdk/cloudml-0.1.6-alpha.dataflow.tar.gz\n",
      "Reading  16384 x 16384  images from  ['input_data/landsat8-b1.tif', 'input_data/landsat8-b2.tif', 'input_data/mcd12-labels.tif']\n"
     ]
    }
   ],
   "source": [
    "import osgeo.gdal as gdal\n",
    "import struct\n",
    "import numpy as np\n",
    "import google.cloud.ml as ml\n",
    "import tensorflow as tf\n",
    "import apache_beam as beam\n",
    "import google.cloud.ml as ml\n",
    "import google.cloud.ml.io as io\n",
    "import google.cloud.ml.features as features\n",
    "import os\n",
    "\n",
    "print tf.__version__\n",
    "print ml.sdk_location\n",
    "\n",
    "\n",
    "def get_pixel_values(filenames, featnames):\n",
    "    \"\"\"\n",
    "    generator function that returns pixel values from all the bands as a dictionary\n",
    "    \"\"\"\n",
    "    ds = [gdal.Open( filename, gdal.GA_ReadOnly)  for filename in filenames]\n",
    "    bands = [ds1.GetRasterBand(1) for ds1 in ds] \n",
    "    ncols = bands[0].XSize\n",
    "    nrows = bands[0].YSize\n",
    "    print \"Reading \", nrows, \"x\", ncols, \" images from \", filenames\n",
    "\n",
    "    packformat = 'f' * ncols\n",
    "    for line in xrange(0, nrows):\n",
    "      line_data = [struct.unpack(packformat, band.ReadRaster(0, line, ncols, 1, ncols, 1, gdal.GDT_Float32)) for band in  bands]\n",
    "      for col in xrange(0, ncols):\n",
    "        result = {}\n",
    "        for f in xrange(0, len(featnames)):\n",
    "          result[featnames[f]] = line_data[f][col]\n",
    "        print result\n",
    "        yield result\n",
    "        \n",
    "class LandcoverFeatures(object):\n",
    "  columns = ('b1', 'b2', 'landcover')\n",
    "  target = features.target('landcover').discrete()  # classification problem\n",
    "  filenames = ['input_data/landsat8-b1.tif', 'input_data/landsat8-b2.tif', 'input_data/mcd12-labels.tif']\n",
    "  inputs = [\n",
    "      features.numeric('b1').identity(),\n",
    "      features.numeric('b2').identity(),\n",
    "      #features.numeric('b3').identity(),\n",
    "      #features.numeric('b4').identity(),\n",
    "      #features.numeric('b5').identity(),\n",
    "      #features.numeric('b6').identity(),\n",
    "      #features.numeric('b7').identity(),\n",
    "      #features.numeric('el').identity(),  # elevation\n",
    "  ]\n",
    "  \n",
    "\n",
    "\n",
    "# defines\n",
    "feature_set = LandcoverFeatures()\n",
    "OUTPUT_DIR = './preproc'\n",
    "pipeline = beam.Pipeline('DirectPipelineRunner')\n",
    "\n",
    "# preprocessing\n",
    "train = pipeline | beam.Create(get_pixel_values(feature_set.filenames, feature_set.columns))\n",
    "(metadata, train_features) = ((train) |\n",
    "   'Preprocess' >> ml.Preprocess(feature_set))\n",
    "\n",
    "(metadata\n",
    "   | 'SaveMetadata'\n",
    "   >> io.SaveMetadata(os.path.join(OUTPUT_DIR, 'metadata.yaml')))\n",
    "(train_features\n",
    "   | 'WriteTraining'\n",
    "   >> io.SaveFeatures(os.path.join(OUTPUT_DIR, 'features_train')))\n",
    "\n",
    "# run pipeline\n",
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
