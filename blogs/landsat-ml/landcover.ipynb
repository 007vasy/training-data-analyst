{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Creating high-resolution Landcover data using Machine Learning </h1>\n",
    "\n",
    "In this notebook, we train a TensorFlow model to fit Landsat 8 bands to a low-resolution landcover map. Then, we use that model on the high-resolution Landsat data to create a high-resolution landcover map. In essence, we are using TensorFlow to <a href=\"https://gisclimatechange.ucar.edu/question/63\">statistically downscale</a> the landcover data (note that the term \"downscaling\" is counterintuitive -- downscaling an image increases its resolution or upsamples it).\n",
    "\n",
    "<div id=\"toc\"></div>\n",
    "\n",
    "<h2> Workflow </h2>\n",
    "We will read corresponding pixels out of a set of mosaiced-and-cloud-corrected Landsat GeoTiff images and correlate them with a low-resolution landcover map that has been upsampled to match the Landsat imagery.  This dataset of pixel values is what is used in training.  In prediction, we take the same set of Landsat images and use the trained model to come up with a high-resolution landcover map.\n",
    "\n",
    "This is the basic workflow:\n",
    "<img src=\"landcover_features.png\" style='width: 100%;' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Preprocessing using Cloud Dataflow </h2>\n",
    "\n",
    "Cloud Dataflow can scale up and simplify preprocessing in Cloud ML.  We'll need to read the Geotiffs and then merge them in such a way that all the data corresponding to a pixel becomes a single TFRecord. We'll scale the pixel values to lie in the range [-1,1]. If you do this sort of thing naively, you'll run out of memory or burn through your wallet -- the total size of the images alone is 25 GB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# a Python generator that packs all the training data line-by-line\n",
    "def get_next_line(SMALL_SAMPLE):\n",
    "  '''\n",
    "      return (lineno, linedata, featnames)\n",
    "      where linedata is a 2D array with first dimension being feature# and second dimension column in image \n",
    "  '''  \n",
    "  import osgeo.gdal as gdal\n",
    "  import struct\n",
    "  import os\n",
    "  import subprocess\n",
    "  \n",
    "  # The gdal library can not read from CloudStorage, so this class downloads the data to local VM\n",
    "  class LandsatReader():\n",
    "   def __init__(self, gsfile, destdir='./'):\n",
    "      self.gsfile = gsfile\n",
    "      self.dest = os.path.join(destdir, os.path.basename(self.gsfile))\n",
    "      if os.path.exists(self.dest):\n",
    "        print 'Using already existing {}'.format(self.dest)\n",
    "      else:\n",
    "        print 'Getting {0} to {1} '.format(self.gsfile, self.dest)\n",
    "        ret = subprocess.check_call(['gsutil', 'cp', self.gsfile, self.dest])\n",
    "      self.dataset = gdal.Open( self.dest, gdal.GA_ReadOnly )\n",
    "   def __exit__(self, exc_type=None, exc_val=None, exc_tb=None):\n",
    "      os.remove( self.dest ) # cleanup  \n",
    "   def ds(self):\n",
    "      return self.dataset\n",
    "\n",
    "  # open all the necessary files\n",
    "  input_dir = 'gs://mdh-test/landsat-ml/'\n",
    "  featnames = ['b{}'.format(band) for band in xrange(1,8)] # 8\n",
    "  filenames = [os.path.join(input_dir, 'landsat8-{}.tif'.format(band)) for band in featnames]\n",
    "  filenames.append(os.path.join(input_dir, 'srtm-elevation.tif')); featnames.append('elev')\n",
    "  filenames.append(os.path.join(input_dir, 'mcd12-labels.tif')); featnames.append('landcover')\n",
    "  readers = [LandsatReader(filename) for filename in filenames]\n",
    "  bands = [reader.ds().GetRasterBand(1) for reader in readers] \n",
    "  print \"Opened \", filenames\n",
    "      \n",
    "  # read one row of each the images and yield them\n",
    "  ncols = bands[0].XSize\n",
    "  nrows = bands[0].YSize\n",
    "  if SMALL_SAMPLE:\n",
    "    nrows_to_read = 200\n",
    "    ncols_to_read = 1000\n",
    "  else:\n",
    "    nrows_to_read = nrows\n",
    "    ncols_to_read = ncols\n",
    "  print \"Reading \", nrows_to_read, \"x\", ncols_to_read, \" from \", nrows, 'x', ncols, ' images corresponding to ', featnames\n",
    "  packformat = 'f' * ncols\n",
    "  for line in xrange(0, nrows_to_read):\n",
    "        line_data = [struct.unpack(packformat, band.ReadRaster(0, line, ncols, 1, ncols, 1, gdal.GDT_Float32)) for band in bands]\n",
    "        yield (line, line_data, featnames, ncols_to_read)\n",
    "      \n",
    "def get_features_from_line(args):\n",
    "  '''\n",
    "      return (1, dict)  or (0, dict)\n",
    "      where the first number is 1 or 0 depending on whether this row belongs to training (1)\n",
    "      or eval (0) partition.\n",
    "      dict is the set of features formed from pixels from all the bands\n",
    "  ''' \n",
    "  (line, line_data, featnames, ncols_to_read) = args\n",
    "  if line_data:\n",
    "    for col in xrange(0, ncols_to_read):\n",
    "          featdict = {'rowcol': '{},{}'.format(line,col)}\n",
    "          for f in xrange(0, len(featnames)):\n",
    "            featdict[featnames[f]] = line_data[f][col]\n",
    "          featdict['landcover'] = '{}'.format(int(featdict['landcover']+0.5))\n",
    "          yield ( 0 if (line+col)%3==0 else 1, featdict )    # 1/3 are eval\n",
    "\n",
    "def get_partition(group_and_featdict, nparts):\n",
    "  (is_train, featdict) = group_and_featdict\n",
    "  return is_train # 0 or 1\n",
    "\n",
    "def get_featdict(group_and_featdict):\n",
    "  (is_train, featdict) = group_and_featdict\n",
    "  return featdict\n",
    "\n",
    "def run_preprocessing(BUCKET=None, PROJECT=None):\n",
    "  import os\n",
    "  import numpy as np\n",
    "  import apache_beam as beam\n",
    "  import google.cloud.ml as ml\n",
    "  import google.cloud.ml.io as io\n",
    "  import google.cloud.ml.features as features\n",
    "\n",
    "  # small sample locally; full dataset on cloud\n",
    "  if BUCKET is None or PROJECT is None:\n",
    "    SMALL_SAMPLE = True\n",
    "    OUTPUT_DIR = './landcover_preproc'\n",
    "    RUNNER = 'DirectPipelineRunner'\n",
    "  else:\n",
    "    SMALL_SAMPLE = False\n",
    "    OUTPUT_DIR = 'gs://{0}/landcover/preproc'.format(BUCKET)\n",
    "    RUNNER = 'DataflowPipelineRunner'\n",
    "  #\n",
    "  \n",
    "  pipeline = beam.Pipeline(argv=['--project', PROJECT,\n",
    "                               '--runner', RUNNER,\n",
    "                               '--job_name', 'landcover',\n",
    "                               '--extra_package', ml.sdk_location,\n",
    "                               '--max_num_workers', '10',\n",
    "                               '--no_save_main_session', 'True',  # to prevent pickling and uploading Datalab itself!\n",
    "                               '--setup_file', './preproc/setup.py',  # for gdal installation on the cloud -- see CUSTOM_COMMANDS in setup.py\n",
    "                               '--staging_location', 'gs://{0}/landcover/staging'.format(BUCKET),\n",
    "                               '--temp_location', 'gs://{0}/landcover/temp'.format(BUCKET)])\n",
    "        \n",
    "  print ml.sdk_location\n",
    "  (evalg, traing) = (pipeline \n",
    "     | beam.Create([SMALL_SAMPLE]) # make the generator function like a source\n",
    "     | beam.FlatMap(get_next_line)\n",
    "     | beam.FlatMap(get_features_from_line) # (is_train, featdict)\n",
    "     | beam.Partition(get_partition, 2)\n",
    "  )  # eval, train both contain (is_train, featdict)\n",
    "  eval = evalg | 'eval_features' >> beam.Map(get_featdict)\n",
    "  train = traing | 'train_features' >> beam.Map(get_featdict)\n",
    "  \n",
    "  class LandcoverFeatures(object):\n",
    "    key = features.key('rowcol')\n",
    "    landcover = features.target('landcover').discrete()  # classification problem\n",
    "    inputbands = [\n",
    "      features.numeric('b1').scale(),\n",
    "      features.numeric('b2').scale(),\n",
    "      features.numeric('b3').scale(),\n",
    "      features.numeric('b4').scale(),\n",
    "      features.numeric('b5').scale(),\n",
    "      features.numeric('b6').scale(),\n",
    "      features.numeric('b7').scale(),\n",
    "      #features.numeric('el').discretize(buckets=[1,5001,50], sparse=True),  # elevation\n",
    "    ]\n",
    "  feature_set = LandcoverFeatures()\n",
    "  (metadata, train_features, eval_features) = ((train, eval) |\n",
    "   'Preprocess' >> ml.Preprocess(feature_set, input_format='json'))\n",
    "  (metadata\n",
    "     | 'SaveMetadata'\n",
    "     >> io.SaveMetadata(os.path.join(OUTPUT_DIR, 'metadata.yaml')))\n",
    "  (train_features\n",
    "     | 'WriteTraining'\n",
    "     >> io.SaveFeatures(os.path.join(OUTPUT_DIR, 'features_train')))\n",
    "  (eval_features\n",
    "     | 'WriteEval'\n",
    "     >> io.SaveFeatures(os.path.join(OUTPUT_DIR, 'features_eval')))\n",
    "  pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Create ML model using TensorFlow </h2>\n",
    "\n",
    "I cheated here. I simply took the <a href=\"https://github.com/GoogleCloudPlatform/cloudml-samples/tree/master/iris\">Cloud ML sample for Iris classification</a> and copied it into my repo.  The only change I had to make was to three fields, changing:\n",
    "<pre>\n",
    "KEY_FEATURE_COLUMN = 'key'\n",
    "TARGET_FEATURE_COLUMN = 'species'\n",
    "REAL_VALUED_FEATURE_COLUMNS = 'measurements'\n",
    "</pre>\n",
    "to\n",
    "<pre>\n",
    "KEY_FEATURE_COLUMN = 'key'\n",
    "TARGET_FEATURE_COLUMN = 'landcover'\n",
    "REAL_VALUED_FEATURE_COLUMNS = 'inputbands'\n",
    "</pre>\n",
    "Essentially, my new values match what I had in the class LandcoverFeatures during preprocessing (see above).  This is needed because that's what now encoded in the tfrecord files the preprocessing step wrote out.\n",
    "\n",
    "The model itself is a neural network with 2 hidden layers. The Iris sample uses the tf.learn API. It is a classification network, and the sample does all the saving, exporting, distribution, etc. All my inputs are like the Iris sample in that they are all real-valued columns. Like in the Iris example, the target takes only one value -- a landcover that is brushland can not also be forest. So, I'm relatively safe in reusing the Iris model as-is.  Of course, I should probably do some feature engineering, by calculating normalized differences, for example. But for now, the Iris sample will suffice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "landcover:\r\n",
      "total 8\r\n",
      "-rw-r--r-- 1 root root  746 Nov  3 18:28 setup.py\r\n",
      "drwxr-xr-x 2 root root 4096 Nov  3 23:07 trainer\r\n",
      "\r\n",
      "landcover/trainer:\r\n",
      "total 24\r\n",
      "-rw-r--r-- 1 root root  677 Nov  3 21:54 __init__.py\r\n",
      "-rw-r--r-- 1 root root 9176 Nov  3 23:07 task.py\r\n",
      "-rw-r--r-- 1 root root 5553 Nov  3 22:51 util.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lR landcover"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Train model locally using Cloud ML </h2>\n",
    "\n",
    "Let's train the model locally on a subset of the data to ensure that we get things right. Then, we can train on the cloud with all of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://cloud-ml/sdk/cloudml-0.1.6-alpha.dataflow.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Direct usage of TextFileSink is deprecated. Please use 'textio.WriteToText()' instead of directly instantiating a TextFileSink object.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using already existing ./landsat8-b1.tif\n",
      "Using already existing ./landsat8-b2.tif\n",
      "Using already existing ./landsat8-b3.tif\n",
      "Using already existing ./landsat8-b4.tif\n",
      "Using already existing ./landsat8-b5.tif\n",
      "Using already existing ./landsat8-b6.tif\n",
      "Using already existing ./landsat8-b7.tif\n",
      "Using already existing ./srtm-elevation.tif\n",
      "Using already existing ./mcd12-labels.tif\n",
      "Opened  ['gs://mdh-test/landsat-ml/landsat8-b1.tif', 'gs://mdh-test/landsat-ml/landsat8-b2.tif', 'gs://mdh-test/landsat-ml/landsat8-b3.tif', 'gs://mdh-test/landsat-ml/landsat8-b4.tif', 'gs://mdh-test/landsat-ml/landsat8-b5.tif', 'gs://mdh-test/landsat-ml/landsat8-b6.tif', 'gs://mdh-test/landsat-ml/landsat8-b7.tif', 'gs://mdh-test/landsat-ml/srtm-elevation.tif', 'gs://mdh-test/landsat-ml/mcd12-labels.tif']\n",
      "Reading  200 x 1000  from  16384 x 16384  images corresponding to  ['b1', 'b2', 'b3', 'b4', 'b5', 'b6', 'b7', 'elev', 'landcover']\n"
     ]
    }
   ],
   "source": [
    "# process a small sample (200k points) by running the preprocessing locally\n",
    "# if your Datalab instance can't handle this, reduce the sample size by changing the preprocessing code\n",
    "# (look for nrows_read and change it from 200 to perhaps 20)\n",
    "# alternately, if you followed the codelab instructions to launch Datalab on a GCE, change the machine\n",
    "# type in instance_details.sh to n1-highmem-2   (should take about 5 minutes on n1-highmem-2)\n",
    "import shutil\n",
    "shutil.rmtree('landcover_preproc', ignore_errors=True)\n",
    "run_preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 7004\r\n",
      "-rw-r--r-- 1 root root 2422582 Nov  4 23:42 features_eval-00000-of-00001.tfrecord.gz\r\n",
      "-rw-r--r-- 1 root root 4740616 Nov  4 23:42 features_train-00000-of-00001.tfrecord.gz\r\n",
      "-rw-r--r-- 1 root root    2086 Nov  4 23:41 metadata.yaml\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l /content/training-data-analyst/blogs/landsat-ml/landcover_preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "landcover/\n",
      "landcover/trainer/\n",
      "landcover/trainer/task.py\n",
      "landcover/trainer/util.py\n",
      "landcover/trainer/__init__.py\n",
      "landcover/setup.py\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "rm -rf /content/training-data-analyst/blogs/landsat-ml/landcover_trained\n",
    "tar cvfz landcover.tgz landcover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>Job Running...</p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/_nocachecontent/master\" target=\"_blank\">master log</a>&nbsp;&nbsp;"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "master: INFO:tensorflow:Transforming feature_column _RealValuedColumn(column_name='inputbands', dimension=7, default_value=None, dtype=tf.float32, normalizer=None)<br/>master: WARNING:tensorflow:Please specify metrics using MetricSpec. Using bare functions or (key, fn) tuples is deprecated and support for it will be removed on Oct 1, 2016.<br/>master: WARNING:tensorflow:Please specify metrics using MetricSpec. Using bare functions or (key, fn) tuples is deprecated and support for it will be removed on Oct 1, 2016.<br/>master: INFO:tensorflow:Restored model from /content/training-data-analyst/blogs/landsat-ml/landcover_trained/train<br/>master: INFO:tensorflow:Eval steps [0,100) for training step 2000.<br/>master: INFO:tensorflow:Results after 10 steps (0.003 sec/batch): loss = 0.86316, training/hptuning/metric = 0.68, accuracy = 0.68.<br/>master: INFO:tensorflow:Results after 20 steps (0.001 sec/batch): loss = 0.938792, training/hptuning/metric = 0.641667, accuracy = 0.641667.<br/>master: INFO:tensorflow:Results after 30 steps (0.001 sec/batch): loss = 0.936572, training/hptuning/metric = 0.655556, accuracy = 0.655556.<br/>master: INFO:tensorflow:Results after 40 steps (0.001 sec/batch): loss = 0.89947, training/hptuning/metric = 0.664167, accuracy = 0.664167.<br/>master: INFO:tensorflow:Results after 50 steps (0.001 sec/batch): loss = 0.903345, training/hptuning/metric = 0.666, accuracy = 0.666.<br/>master: INFO:tensorflow:Results after 60 steps (0.001 sec/batch): loss = 0.894385, training/hptuning/metric = 0.673889, accuracy = 0.673889.<br/>master: INFO:tensorflow:Results after 70 steps (0.001 sec/batch): loss = 0.897772, training/hptuning/metric = 0.67, accuracy = 0.67.<br/>master: INFO:tensorflow:Results after 80 steps (0.001 sec/batch): loss = 0.892392, training/hptuning/metric = 0.67, accuracy = 0.67.<br/>master: INFO:tensorflow:Results after 90 steps (0.001 sec/batch): loss = 0.894256, training/hptuning/metric = 0.667778, accuracy = 0.667778.<br/>master: INFO:tensorflow:Results after 100 steps (0.001 sec/batch): loss = 0.892895, training/hptuning/metric = 0.665667, accuracy = 0.665667.<br/>master: W tensorflow/core/kernels/queue_base.cc:294] _9_batch/fifo_queue: Skipping cancelled enqueue attempt with queue not closed<br/>master: W tensorflow/core/kernels/queue_base.cc:294] _9_batch/fifo_queue: Skipping cancelled enqueue attempt with queue not closed<br/>master: W tensorflow/core/kernels/queue_base.cc:294] _11_input_producer: Skipping cancelled enqueue attempt with queue not closed<br/>master: INFO:tensorflow:Saving evaluation summary for 2000 step: loss = 0.892895, training/hptuning/metric = 0.665667, accuracy = 0.665667<br/>master: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>Job Finished.</p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%mlalpha train\n",
    "package_uris: /content/training-data-analyst/blogs/landsat-ml/landcover.tgz\n",
    "python_module: trainer.task\n",
    "scale_tier: BASIC\n",
    "region: us-central1\n",
    "args:\n",
    "  train_data_paths: /content/training-data-analyst/blogs/landsat-ml/landcover_preproc/features_train-*\n",
    "  eval_data_paths: /content/training-data-analyst/blogs/landsat-ml/landcover_preproc/features_eval-*\n",
    "  metadata_path: /content/training-data-analyst/blogs/landsat-ml/landcover_preproc/metadata.yaml\n",
    "  output_path: /content/training-data-analyst/blogs/landsat-ml/landcover_trained\n",
    "  max_steps:  2000\n",
    "  batch_size: 10000\n",
    "  layer1_size: 30\n",
    "  layer2_size: 10\n",
    "  learning_rate: 0.01\n",
    "  min_eval_frequency: 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Predict with locally trained model</h3>\n",
    "\n",
    "We can use the preprocessed features to evaluate how well the trained model performs. The evaluation workflow will use the model for prediction, so if we save the predictions from the model when it is being evaluated, we can use those predictions for downscaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_eval-00000-of-00001.tfrecord.gz   metadata.yaml\r\n",
      "features_train-00000-of-00001.tfrecord.gz\r\n"
     ]
    }
   ],
   "source": [
    "!ls /content/training-data-analyst/blogs/landsat-ml/landcover_preproc/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Direct usage of TextFileSink is deprecated. Please use 'textio.WriteToText()' instead of directly instantiating a TextFileSink object.\n",
      "WARNING:root:Direct usage of TextFileSink is deprecated. Please use 'textio.WriteToText()' instead of directly instantiating a TextFileSink object.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<apache_beam.runners.direct_runner.DirectPipelineResult at 0x7f3fd40eff50>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imports\n",
    "import apache_beam as beam\n",
    "import google.cloud.ml as ml\n",
    "import google.cloud.ml.analysis as analysis\n",
    "import google.cloud.ml.io as io\n",
    "import json\n",
    "import os\n",
    "\n",
    "OUTPUT_DIR = '/content/training-data-analyst/blogs/landsat-ml/landcover_eval'\n",
    "pipeline = beam.Pipeline('DirectPipelineRunner')\n",
    "\n",
    "eval_features = (pipeline | 'ReadEval' >> io.LoadFeatures('/content/training-data-analyst/blogs/landsat-ml/landcover_preproc/features_eval*'))\n",
    "trained_model = pipeline | 'LoadModel' >> io.LoadModel('/content/training-data-analyst/blogs/landsat-ml/landcover_trained/model')\n",
    "evaluations = (eval_features | 'Evaluate' >> ml.Evaluate(trained_model) |\n",
    "    beam.Map('ExtractEvaluationResults', lambda (example, prediction): prediction))\n",
    "eval_data_sink = beam.io.TextFileSink(os.path.join(OUTPUT_DIR, 'eval'), shard_name_template='')\n",
    "evaluations | beam.io.textio.WriteToText(os.path.join(OUTPUT_DIR, 'eval'), shard_name_template='')\n",
    "\n",
    "# run pipeline\n",
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'score': [0.9201728701591492, 0.005093369632959366, 6.252119055716321e-05, 0.011211490258574486, 0.055562522262334824, 0.007897143252193928], u'target': '1', u'key': '0,0', u'label': '1'}\r\n",
      "{u'score': [0.9550836682319641, 0.0030277296900749207, 2.1692805603379384e-05, 0.009645896032452583, 0.02988329716026783, 0.0023376329336315393], u'target': '1', u'key': '0,3', u'label': '1'}\r\n"
     ]
    }
   ],
   "source": [
    "!head -2 /content/training-data-analyst/blogs/landsat-ml/landcover_eval/eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the output includes the key (the pixel location), and the label (the prediction) for that pixel. That is enough for us to be able to do the downscaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Using fallback coder for typehint: <type 'function'>.\n",
      "WARNING:root:Direct usage of TextFileSink is deprecated. Please use 'textio.WriteToText()' instead of directly instantiating a TextFileSink object.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': 0, '10': 1, '12': 2, '5': 3, '9': 5, '8': 4}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<apache_beam.runners.direct_runner.DirectPipelineResult at 0x7f400b226290>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imports\n",
    "import apache_beam as beam\n",
    "import google.cloud.ml as ml\n",
    "import google.cloud.ml.analysis as analysis\n",
    "import google.cloud.ml.io as io\n",
    "import json\n",
    "import yaml\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "OUTPUT_DIR = '/content/training-data-analyst/blogs/landsat-ml/landcover_eval'\n",
    "pipeline = beam.Pipeline('DirectPipelineRunner')\n",
    "\n",
    "# analysis\n",
    "def read_metadata(filename):\n",
    "  with open(filename, 'r') as stream:\n",
    "    try:\n",
    "        return yaml.load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)\n",
    "\n",
    "metadata = read_metadata('/content/training-data-analyst/blogs/landsat-ml/landcover_preproc/metadata.yaml')\n",
    "lookup = metadata['columns']['landcover']['vocab']\n",
    "print lookup\n",
    "def make_data_for_analysis(values):\n",
    "  return {\n",
    "      'target': lookup[values['target']],\n",
    "      'predicted': lookup[values['label']],\n",
    "      'score': np.max(values['score']), # not needed\n",
    "  }\n",
    "\n",
    "metadata = pipeline | io.LoadMetadata('/content/training-data-analyst/blogs/landsat-ml/landcover_preproc/metadata.yaml')\n",
    "analysis_source = evaluations | beam.Map('CreateAnalysisSource', make_data_for_analysis)\n",
    "confusion_matrix, precision_recall, logloss = (analysis_source |\n",
    "    'Analyze Model' >> analysis.AnalyzeModel(metadata))\n",
    "confusion_matrix_file = os.path.join(OUTPUT_DIR, 'analyze_cm.json')\n",
    "confusion_matrix_sink = beam.io.TextFileSink(confusion_matrix_file, shard_name_template='')\n",
    "confusion_matrix | beam.io.Write('WriteConfusionMatrix', confusion_matrix_sink)\n",
    "\n",
    "\n",
    "# run pipeline\n",
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"5e22cd4b-eab0-4c7d-9233-0a1b273ee2d8\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"5e22cd4b-eab0-4c7d-9233-0a1b273ee2d8\", [{\"y\": [\"lc_09\", \"lc_08\", \"lc_10\", \"lc_12\", \"lc_05\", \"lc_01\"], \"x\": [\"lc_09\", \"lc_08\", \"lc_10\", \"lc_12\", \"lc_05\", \"lc_01\"], \"z\": [[5347, 1712, 246, 4, 0, 4693], [1990, 18316, 1462, 6, 0, 1307], [297, 1610, 5389, 2, 0, 79], [29, 81, 28, 7, 0, 3], [84, 1, 0, 0, 0, 1880], [2355, 183, 10, 0, 0, 19546]], \"type\": \"heatmap\", \"colorscale\": \"YlGnBu\"}], {\"title\": \"Confusion Matrix\", \"xaxis\": {\"title\": \"Predicted value\"}, \"yaxis\": {\"title\": \"True Value\"}}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datalab.mlalpha\n",
    "import yaml\n",
    "with ml.util._file.open_local_or_gcs(confusion_matrix_file, 'r') as f:\n",
    "  data = [yaml.load(line) for line in f.read().rstrip().split('\\n')]\n",
    "  for line in data:\n",
    "    line['target'] = 'lc_{:02d}'.format(int(line['target']))\n",
    "    line['predicted'] = 'lc_{:02d}'.format(int(line['predicted']))\n",
    "datalab.mlalpha.ConfusionMatrix([d['predicted'] for d in data],\n",
    "                           [d['target'] for d in data],\n",
    "                           [d['count'] for d in data]).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model seems to get a little confused between categories 1 and 9; categories 5 and 12 are poorly recognized. Let's not get too hung up on this, though, because this is on a very small dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Train on full dataset on the cloud</h2>\n",
    "\n",
    "Let's preprocess the complete dataset.  <b>These steps will take several hours and have billing implications</b>.\n",
    "\n",
    "Specify your bucket and project as appropriate. Make sure that the bucket you use is a single-region bucket (when you create a bucket, there is an option to specify this). If you already have a bucket and it is not a single-region one, you should create a separate single-region bucket for Cloud ML jobs to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!python preprocess.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Updates are available for some Cloud SDK components.  To install them,\n",
      "please run:\n",
      "  $ gcloud components update\n",
      "\n",
      "  11911414  2016-11-04T18:12:29Z  gs://cloud-training-demos-ml/landcover/preproc/features_eval-00000-of-00017.tfrecord.gz\n",
      "   1399595  2016-11-04T18:12:29Z  gs://cloud-training-demos-ml/landcover/preproc/features_eval-00001-of-00017.tfrecord.gz\n",
      "    722332  2016-11-04T18:12:29Z  gs://cloud-training-demos-ml/landcover/preproc/features_eval-00002-of-00017.tfrecord.gz\n",
      "  61908282  2016-11-04T18:12:29Z  gs://cloud-training-demos-ml/landcover/preproc/features_eval-00003-of-00017.tfrecord.gz\n",
      "  62458050  2016-11-04T18:12:29Z  gs://cloud-training-demos-ml/landcover/preproc/features_eval-00004-of-00017.tfrecord.gz\n",
      " 233743299  2016-11-04T18:12:29Z  gs://cloud-training-demos-ml/landcover/preproc/features_eval-00005-of-00017.tfrecord.gz\n",
      "   5783557  2016-11-04T18:12:29Z  gs://cloud-training-demos-ml/landcover/preproc/features_eval-00006-of-00017.tfrecord.gz\n",
      " 130264412  2016-11-04T18:12:29Z  gs://cloud-training-demos-ml/landcover/preproc/features_eval-00007-of-00017.tfrecord.gz\n",
      "  23244901  2016-11-04T18:12:29Z  gs://cloud-training-demos-ml/landcover/preproc/features_eval-00008-of-00017.tfrecord.gz\n",
      "1065181613  2016-11-04T18:12:29Z  gs://cloud-training-demos-ml/landcover/preproc/features_eval-00009-of-00017.tfrecord.gz\n",
      " 277395943  2016-11-04T18:12:29Z  gs://cloud-training-demos-ml/landcover/preproc/features_eval-00010-of-00017.tfrecord.gz\n",
      "  28719629  2016-11-04T18:12:29Z  gs://cloud-training-demos-ml/landcover/preproc/features_eval-00011-of-00017.tfrecord.gz\n",
      "1050966190  2016-11-04T18:12:29Z  gs://cloud-training-demos-ml/landcover/preproc/features_eval-00012-of-00017.tfrecord.gz\n",
      "  78715409  2016-11-04T18:12:29Z  gs://cloud-training-demos-ml/landcover/preproc/features_eval-00013-of-00017.tfrecord.gz\n",
      " 130639900  2016-11-04T18:12:29Z  gs://cloud-training-demos-ml/landcover/preproc/features_eval-00014-of-00017.tfrecord.gz\n",
      "    310832  2016-11-04T18:12:29Z  gs://cloud-training-demos-ml/landcover/preproc/features_eval-00015-of-00017.tfrecord.gz\n",
      "   2787529  2016-11-04T18:12:29Z  gs://cloud-training-demos-ml/landcover/preproc/features_eval-00016-of-00017.tfrecord.gz\n",
      " 443549311  2016-11-04T18:12:59Z  gs://cloud-training-demos-ml/landcover/preproc/features_train-00000-of-00024.tfrecord.gz\n",
      "   1192011  2016-11-04T18:12:59Z  gs://cloud-training-demos-ml/landcover/preproc/features_train-00001-of-00024.tfrecord.gz\n",
      "  35677789  2016-11-04T18:12:59Z  gs://cloud-training-demos-ml/landcover/preproc/features_train-00002-of-00024.tfrecord.gz\n",
      "1038657615  2016-11-04T18:12:59Z  gs://cloud-training-demos-ml/landcover/preproc/features_train-00003-of-00024.tfrecord.gz\n",
      " 199716840  2016-11-04T18:12:59Z  gs://cloud-training-demos-ml/landcover/preproc/features_train-00004-of-00024.tfrecord.gz\n",
      "  45670895  2016-11-04T18:12:59Z  gs://cloud-training-demos-ml/landcover/preproc/features_train-00005-of-00024.tfrecord.gz\n",
      "   4878803  2016-11-04T18:12:59Z  gs://cloud-training-demos-ml/landcover/preproc/features_train-00006-of-00024.tfrecord.gz\n",
      "  16880155  2016-11-04T18:12:59Z  gs://cloud-training-demos-ml/landcover/preproc/features_train-00007-of-00024.tfrecord.gz\n",
      " 295734304  2016-11-04T18:12:59Z  gs://cloud-training-demos-ml/landcover/preproc/features_train-00008-of-00024.tfrecord.gz\n",
      "   2526618  2016-11-04T18:12:59Z  gs://cloud-training-demos-ml/landcover/preproc/features_train-00009-of-00024.tfrecord.gz\n",
      "1046941812  2016-11-04T18:12:59Z  gs://cloud-training-demos-ml/landcover/preproc/features_train-00010-of-00024.tfrecord.gz\n",
      "   1436843  2016-11-04T18:12:59Z  gs://cloud-training-demos-ml/landcover/preproc/features_train-00011-of-00024.tfrecord.gz\n",
      "  25896955  2016-11-04T18:12:59Z  gs://cloud-training-demos-ml/landcover/preproc/features_train-00012-of-00024.tfrecord.gz\n",
      " 199163307  2016-11-04T18:12:59Z  gs://cloud-training-demos-ml/landcover/preproc/features_train-00013-of-00024.tfrecord.gz\n",
      "1053759092  2016-11-04T18:12:59Z  gs://cloud-training-demos-ml/landcover/preproc/features_train-00014-of-00024.tfrecord.gz\n",
      "  22568405  2016-11-04T18:12:59Z  gs://cloud-training-demos-ml/landcover/preproc/features_train-00015-of-00024.tfrecord.gz\n",
      "   2890711  2016-11-04T18:12:59Z  gs://cloud-training-demos-ml/landcover/preproc/features_train-00016-of-00024.tfrecord.gz\n",
      " 481782889  2016-11-04T18:12:59Z  gs://cloud-training-demos-ml/landcover/preproc/features_train-00017-of-00024.tfrecord.gz\n",
      "  39446244  2016-11-04T18:12:59Z  gs://cloud-training-demos-ml/landcover/preproc/features_train-00018-of-00024.tfrecord.gz\n",
      " 107611947  2016-11-04T18:12:59Z  gs://cloud-training-demos-ml/landcover/preproc/features_train-00019-of-00024.tfrecord.gz\n",
      " 154284477  2016-11-04T18:12:59Z  gs://cloud-training-demos-ml/landcover/preproc/features_train-00020-of-00024.tfrecord.gz\n",
      "    747465  2016-11-04T18:12:59Z  gs://cloud-training-demos-ml/landcover/preproc/features_train-00021-of-00024.tfrecord.gz\n",
      "1035094056  2016-11-04T18:12:59Z  gs://cloud-training-demos-ml/landcover/preproc/features_train-00022-of-00024.tfrecord.gz\n",
      "    790420  2016-11-04T18:12:59Z  gs://cloud-training-demos-ml/landcover/preproc/features_train-00023-of-00024.tfrecord.gz\n",
      "      2243  2016-11-04T16:57:07Z  gs://cloud-training-demos-ml/landcover/preproc/metadata.yaml\n",
      "TOTAL: 42 objects, 9423054094 bytes (8.78 GiB)\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls -l gs://cloud-training-demos-ml/landcover/preproc/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tar up the Python package and make it available on Cloud Storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "landcover/\n",
      "landcover/setup.py\n",
      "landcover/trainer/\n",
      "landcover/trainer/__init__.py\n",
      "landcover/trainer/task.py\n",
      "landcover/trainer/util.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CommandException: 1 files/objects could not be removed.\n",
      "Copying file://landcover.tgz [Content-Type=application/x-tar]...\n",
      "/ [0 files][    0.0 B/  5.0 KiB]                                                \r",
      "/ [1 files][  5.0 KiB/  5.0 KiB]                                                \r\n",
      "Operation completed over 1 objects/5.0 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "BUCKET=cloud-training-demos-ml\n",
    "gsutil -m rm -rf gs://$BUCKET/landcover/trained\n",
    "tar cvfz landcover.tgz landcover\n",
    "gsutil cp landcover.tgz gs://$BUCKET/landcover/source/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the same as the local training except:\n",
    "<ol>\n",
    "<li> --cloud parameter to do the training on the Cloud in a distributed way rather on a single machine.\n",
    "<li> all the data paths point to Cloud Storage, where our preprocessing code wrote its output\n",
    "<li> max_steps is much larger.  This is because a step is only one batch.  The entire dataset is 178m points, and since batchsize is 10000, we need\n",
    "17,800 steps for a single epoch (or pass through training data).  So, the 890000 here is approximately 50 epochs of training.\n",
    "<li> The evaluation frequency has been upped to 17,800 for the same reason (so that we evaluate approximately once every epoch)\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>Job \"trainer_task_161121_170420\" was submitted successfully.<br/>Run \"%mlalpha jobs --name trainer_task_161121_170420\" to view the status of the job.</p><p>Click <a href=\"https://console.developers.google.com/logs/viewer?project=cloud-training-demos&resource=ml.googleapis.com%2Fjob_id%2Ftrainer_task_161121_170420\" target=\"_blank\">here</a> to view cloud log. <br/>Start TensorBoard by running \"%tensorboard start --logdir=&lt;YourLogDir&gt;\".</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%mlalpha train --cloud\n",
    "package_uris: gs://cloud-training-demos-ml/landcover/source/landcover.tgz\n",
    "python_module: trainer.task\n",
    "scale_tier: STANDARD_1\n",
    "region: us-central1\n",
    "args:\n",
    "  train_data_paths: gs://cloud-training-demos-ml/landcover/preproc/features_train-*\n",
    "  eval_data_paths: gs://cloud-training-demos-ml/landcover/preproc/features_eval-*\n",
    "  metadata_path: gs://cloud-training-demos-ml/landcover/preproc/metadata.yaml\n",
    "  output_path: gs://cloud-training-demos-ml/landcover/trained\n",
    "  max_steps:  890000\n",
    "  batch_size: 10000\n",
    "  layer1_size: 30\n",
    "  layer2_size: 10\n",
    "  learning_rate: 0.01\n",
    "  min_eval_frequency: 17800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>createTime: '2016-11-21T17:04:14Z'\n",
       "endTime: '2016-11-21T17:49:53Z'\n",
       "jobId: trainer_task_161121_170420\n",
       "startTime: '2016-11-21T17:04:44Z'\n",
       "state: SUCCEEDED\n",
       "trainingInput:\n",
       "  args: [--metadata_path, 'gs://cloud-training-demos-ml/landcover/preproc/metadata.yaml',\n",
       "    --min_eval_frequency, '17800', --batch_size, '10000', --eval_data_paths, 'gs://cloud-training-demos-ml/landcover/preproc/features_eval-*',\n",
       "    --layer1_size, '30', --output_path, 'gs://cloud-training-demos-ml/landcover/trained',\n",
       "    --train_data_paths, 'gs://cloud-training-demos-ml/landcover/preproc/features_train-*',\n",
       "    --max_steps, '890000', --learning_rate, '0.01', --layer2_size, '10']\n",
       "  packageUris: ['gs://cloud-training-demos-ml/landcover/source/landcover.tgz']\n",
       "  pythonModule: trainer.task\n",
       "  region: us-central1\n",
       "  scaleTier: STANDARD_1\n",
       "</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%mlalpha jobs --name trainer_task_161121_170420"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Updates are available for some Cloud SDK components.  To install them,\n",
      "please run:\n",
      "  $ gcloud components update\n",
      "\n",
      "gs://cloud-training-demos-ml/landcover/trained/model/\n",
      "gs://cloud-training-demos-ml/landcover/trained/model/checkpoint\n",
      "gs://cloud-training-demos-ml/landcover/trained/model/export\n",
      "gs://cloud-training-demos-ml/landcover/trained/model/export.meta\n",
      "gs://cloud-training-demos-ml/landcover/trained/model/metadata.yaml\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls gs://cloud-training-demos-ml/landcover/trained/model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Run prediction </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!python predict.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://cloud-training-demos-ml/landcover/prediction/eval\n",
      "gs://cloud-training-demos-ml/landcover/prediction/tmp/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing gs://cloud-training-demos-ml/landcover/prediction/landcover.TIF...\n",
      "/ [1 objects]                                                                   \r\n",
      "Operation completed over 1 objects.                                              \n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "gsutil rm gs://cloud-training-demos-ml/landcover/prediction/landcover.TIF\n",
    "gsutil ls gs://cloud-training-demos-ml/landcover/prediction/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Confusion matrix </h2>\n",
    "\n",
    "Let's display the confusion matrix on the full prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://cloud-training-demos-ml/landcover/trained/model/metadata.yaml...\n",
      "- [1 files][  2.2 KiB/  2.2 KiB]                                                \n",
      "Operation completed over 1 objects/2.2 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp gs://cloud-training-demos-ml/landcover/trained/model/metadata.yaml /tmp/metadata.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'11': 3, '10': 2, '13': 5, '12': 4, '15': 7, '14': 6, '16': 8, '1': 1, '0': 0, '3': 10, '2': 9, '5': 12, '4': 11, '7': 14, '6': 13, '9': 16, '8': 15}\n"
     ]
    }
   ],
   "source": [
    "# analysis\n",
    "def read_metadata(filename): \n",
    "  import yaml\n",
    "  with open(filename, 'r') as stream:\n",
    "    try:\n",
    "        return yaml.load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)\n",
    "\n",
    "metadata = read_metadata('/tmp/metadata.yaml')\n",
    "lookup = metadata['columns']['landcover']['vocab']\n",
    "print lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://cloud-training-demos-ml/landcover/trained/model/metadata.yaml...\n",
      "/ [1 files][  2.2 KiB/  2.2 KiB]                                                \n",
      "Operation completed over 1 objects/2.2 KiB.                                      \n",
      "Traceback (most recent call last):\n",
      "  File \"confusion.py\", line 60, in <module>\n",
      "    create_confusion_matrix()\n",
      "  File \"confusion.py\", line 52, in create_confusion_matrix\n",
      "    'Analyze Model' >> analysis.AnalyzeModel(metadata))\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/apache_beam/pvalue.py\", line 89, in __or__\n",
      "    return self.pipeline.apply(ptransform, self)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/apache_beam/pipeline.py\", line 199, in apply\n",
      "    label or transform.label)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/apache_beam/pipeline.py\", line 209, in apply\n",
      "    return self.apply(transform, pvalueish)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/apache_beam/pipeline.py\", line 245, in apply\n",
      "    pvalueish_result = self.runner.apply(transform, pvalueish)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/apache_beam/runners/runner.py\", line 147, in apply\n",
      "    return m(transform, input)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/apache_beam/runners/runner.py\", line 153, in apply_PTransform\n",
      "    return transform.apply(input)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/google/cloud/ml/dataflow/_analyzer.py\", line 241, in apply\n",
      "    self._metadata | 'GetLabels' >> GetTargetIndiciesToLabels())\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/apache_beam/transforms/ptransform.py\", line 729, in __ror__\n",
      "    return self.transform.__ror__(pvalueish, self.label)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/apache_beam/transforms/ptransform.py\", line 433, in __ror__\n",
      "    for ix, v in enumerate(pvalues)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/apache_beam/transforms/ptransform.py\", line 434, in <dictcomp>\n",
      "    if not isinstance(v, pvalue.PValue) and v is not None}\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/apache_beam/transforms/core.py\", line 1303, in __init__\n",
      "    self.value = tuple(value)\n",
      "TypeError: 'int' object is not iterable\n"
     ]
    }
   ],
   "source": [
    "!python confusion.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datalab.mlalpha\n",
    "import yaml\n",
    "confusion_matrix_file = 'gs://cloud-training-demos-ml/landcover/prediction/confusion/analyze_cm.json'\n",
    "with ml.util._file.open_local_or_gcs(confusion_matrix_file, 'r') as f:\n",
    "  data = [yaml.load(line) for line in f.read().rstrip().split('\\n')]\n",
    "  for line in data:\n",
    "    line['target'] = 'lc_{:02d}'.format(int(line['target']))\n",
    "    line['predicted'] = 'lc_{:02d}'.format(int(line['predicted']))\n",
    "datalab.mlalpha.ConfusionMatrix([d['predicted'] for d in data],\n",
    "                           [d['target'] for d in data],\n",
    "                           [d['count'] for d in data]).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Create downscaled Landcover image </h2>\n",
    "\n",
    "We'll read the original Landcover image and replace the pixel values by the predictions from the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://cloud-ml/sdk/cloudml-0.1.6-alpha.dataflow.tar.gz\n",
      "in-memory array created ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Error while visiting Map(<lambda at <ipython-input-15-2d2038444d71>:96>)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-2d2038444d71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0mwrite_geotiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpixel_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gs://cloud-training-demos-ml/landcover/prediction/landcover.TIF'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m \u001b[0mcreate_downscaled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-2d2038444d71>\u001b[0m in \u001b[0;36mcreate_downscaled\u001b[0;34m()\u001b[0m\n\u001b[1;32m     97\u001b[0m   ) #\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m   \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m   \u001b[0mwrite_geotiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpixel_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gs://cloud-training-demos-ml/landcover/prediction/landcover.TIF'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/apache_beam/pipeline.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    157\u001b[0m       \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmpdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/apache_beam/runners/dataflow_runner.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, pipeline)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapiclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;31m# The superclass's run will trigger a traversal of all reachable nodes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataflowPipelineRunner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0;31m# Get a Dataflow API client and submit the job.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mstandard_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStandardOptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/apache_beam/runners/runner.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, pipeline)\u001b[0m\n\u001b[1;32m     96\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRunVisitor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/apache_beam/pipeline.pyc\u001b[0m in \u001b[0;36mvisit\u001b[0;34m(self, visitor)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0mvisited\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_root_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvisitor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisited\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpvalueish\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/apache_beam/pipeline.pyc\u001b[0m in \u001b[0;36mvisit\u001b[0;34m(self, visitor, pipeline, visited)\u001b[0m\n\u001b[1;32m    417\u001b[0m       \u001b[0mvisitor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_composite_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mpart\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0mpart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvisitor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisited\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m       \u001b[0mvisitor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleave_composite_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/apache_beam/pipeline.pyc\u001b[0m in \u001b[0;36mvisit\u001b[0;34m(self, visitor, pipeline, visited)\u001b[0m\n\u001b[1;32m    420\u001b[0m       \u001b[0mvisitor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleave_composite_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m       \u001b[0mvisitor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;31m# Visit the outputs (one or more). It is essential to mark as visited the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/apache_beam/runners/runner.pyc\u001b[0m in \u001b[0;36mvisit_transform\u001b[0;34m(self, transform_node)\u001b[0m\n\u001b[1;32m     91\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mvisit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m           \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Error while visiting %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/apache_beam/runners/runner.pyc\u001b[0m in \u001b[0;36mrun_transform\u001b[0;34m(self, transform_node)\u001b[0m\n\u001b[1;32m    166\u001b[0m       \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'run_%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m     raise NotImplementedError(\n\u001b[1;32m    170\u001b[0m         'Execution of [%s] not implemented in runner %s.' % (\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/apache_beam/runners/dataflow_runner.pyc\u001b[0m in \u001b[0;36mrun_ParDo\u001b[0;34m(self, transform_node)\u001b[0m\n\u001b[1;32m    391\u001b[0m         transform_node.transform.side_output_tags)\n\u001b[1;32m    392\u001b[0m     \u001b[0mfn_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pardo_fn_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookup_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m     \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_property\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPropertyNames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSERIALIZED_FN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m     step.add_property(\n\u001b[1;32m    395\u001b[0m         \u001b[0mPropertyNames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPARALLEL_INPUT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/apache_beam/internal/apiclient.pyc\u001b[0m in \u001b[0;36madd_property\u001b[0;34m(self, name, value, with_type)\u001b[0m\n\u001b[1;32m     63\u001b[0m     self.proto.properties.additionalProperties.append(\n\u001b[1;32m     64\u001b[0m         dataflow.Step.PropertiesValue.AdditionalProperty(\n\u001b[0;32m---> 65\u001b[0;31m             key=name, value=to_json_value(value, with_type=with_type)))\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/apache_beam/internal/json_value.pyc\u001b[0m in \u001b[0;36mto_json_value\u001b[0;34m(obj, with_type)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mto_json_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_typed_value_descriptor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mextra_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJsonValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mextra_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJsonValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboolean_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/apitools/base/protorpclite/messages.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0massigned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 793\u001b[0;31m             \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    794\u001b[0m             \u001b[0massigned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/apitools/base/protorpclite/messages.pyc\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m    973\u001b[0m         \"\"\"\n\u001b[1;32m    974\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__by_name\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_Message__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    976\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m             raise AttributeError(\"May not assign arbitrary value %s \"\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/apitools/base/protorpclite/messages.pyc\u001b[0m in \u001b[0;36m__set__\u001b[0;34m(self, message_instance, value)\u001b[0m\n\u001b[1;32m   1301\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m                 value = (  # pylint: disable=redefined-variable-type\n\u001b[0;32m-> 1303\u001b[0;31m                     self.validate(value))\n\u001b[0m\u001b[1;32m   1304\u001b[0m             \u001b[0mmessage_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Message__tags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/apitools/base/protorpclite/messages.pyc\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   1409\u001b[0m           \u001b[0mValidationError\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mexpected\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1410\u001b[0m         \"\"\"\n\u001b[0;32m-> 1411\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalidate_default_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/apitools/base/protorpclite/messages.pyc\u001b[0m in \u001b[0;36m__validate\u001b[0;34m(self, value, validate_element)\u001b[0m\n\u001b[1;32m   1367\u001b[0m         \"\"\"\n\u001b[1;32m   1368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1369\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mvalidate_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1370\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m             \u001b[0;31m# Must be a list or tuple, may not be a string.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/apitools/base/protorpclite/messages.pyc\u001b[0m in \u001b[0;36mvalidate_element\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   1537\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1538\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1539\u001b[0;31m                 \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1540\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mUnicodeDecodeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1541\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def write_geotiff(predictions, outfilename):\n",
    "  '''\n",
    "      predictions should be a np.array([nrows, ncols], dtype=np.float32)\n",
    "      return (lineno, linedata, featnames)\n",
    "      where linedata is a 2D array with first dimension being feature# and second dimension column in image \n",
    "  '''  \n",
    "  import osgeo.gdal as gdal\n",
    "  import struct\n",
    "  import tempfile\n",
    "  import os\n",
    "  import subprocess\n",
    "  \n",
    "  # The gdal library can not read from CloudStorage, so this class downloads the data to local VM\n",
    "  class LandsatReader():\n",
    "   def __init__(self, gsfile, destdir='./'):\n",
    "      self.gsfile = gsfile\n",
    "      self.dest = os.path.join(destdir, os.path.basename(self.gsfile))\n",
    "      if os.path.exists(self.dest):\n",
    "        print 'Using already existing {}'.format(self.dest)\n",
    "      else:\n",
    "        print 'Getting {0} to {1} '.format(self.gsfile, self.dest)\n",
    "        ret = subprocess.check_call(['gsutil', 'cp', self.gsfile, self.dest])\n",
    "      self.dataset = gdal.Open( self.dest, gdal.GA_ReadOnly )\n",
    "   def __exit__(self, exc_type=None, exc_val=None, exc_tb=None):\n",
    "      os.remove( self.dest ) # cleanup  \n",
    "   def ds(self):\n",
    "      return self.dataset\n",
    "\n",
    "  # use the original Landcover file to get the headers etc. correct\n",
    "  input_dir = 'gs://mdh-test/landsat-ml/'\n",
    "  filename = os.path.join(input_dir, 'mcd12-labels.tif')\n",
    "  reader = LandsatReader(filename)\n",
    "  inds = reader.ds()\n",
    "  inband = inds.GetRasterBand(1) \n",
    "  tmpfilename = os.path.join(tempfile.gettempdir(), 'landcover.TIF')\n",
    "  driver = gdal.GetDriverByName('GTiff')\n",
    "  outdtype = gdal.GDT_Float32\n",
    "  outds = driver.Create(tmpfilename, inds.RasterXSize, inds.RasterYSize, 1, outdtype)\n",
    "  outds.SetGeoTransform(inds.GetGeoTransform())\n",
    "  outds.SetProjection(inds.GetProjection())\n",
    "\n",
    "  # fill in data, and write out the file line-by-line\n",
    "  ncols = inband.XSize\n",
    "  nrows = inband.YSize\n",
    "  packformat = 'f' * ncols\n",
    "  for line in xrange(0, nrows):\n",
    "    if line % 10 == 0:\n",
    "      print \"line_{} written ...\".format(line)\n",
    "    outline = struct.pack(packformat, *(predictions[line]))\n",
    "    outds.GetRasterBand(1).WriteRaster(0, line, ncols, 1, outline, buf_xsize=ncols, buf_ysize=1, buf_type=outdtype)\n",
    "    del outline\n",
    "  outds = None # close\n",
    "  ret = subprocess.check_call(['gsutil', 'mv', tmpfilename, outfilename])\n",
    "  print 'Wrote {0} ...'.format(outfilename)\n",
    " \n",
    "def set_pixel_from(pixel_predictions, s):\n",
    "  row, col = s['key'].split(',')\n",
    "  newval = int(s['label'])\n",
    "  pixel_predictions[row,col] = newval\n",
    "    \n",
    "def create_downscaled():\n",
    "  import os\n",
    "  import numpy as np\n",
    "  import apache_beam as beam\n",
    "  import google.cloud.ml as ml\n",
    "  import google.cloud.ml.io as io\n",
    "  import google.cloud.ml.features as features\n",
    "  import json\n",
    "  from StringIO import StringIO\n",
    "\n",
    "  BUCKET = 'cloud-training-demos-ml'\n",
    "  PROJECT = 'cloud-training-demos'\n",
    "  #RUNNER = 'DirectPipelineRunner'\n",
    "  #INPUT = '/content/training-data-analyst/blogs/landsat-ml/landcover_eval/eval*'\n",
    "  RUNNER = 'DataflowPipelineRunner'\n",
    "  INPUT = 'gs://cloud-training-demos-ml/landcover/prediction/eval*'\n",
    "  \n",
    "  pipeline = beam.Pipeline(argv=['--project', PROJECT,\n",
    "                               '--runner', RUNNER,\n",
    "                               '--job_name', 'landcover',\n",
    "                               '--extra_package', ml.sdk_location,\n",
    "                               '--max_num_workers', '10',\n",
    "                               '--no_save_main_session', 'True',  # to prevent pickling and uploading Datalab itself!\n",
    "                               '--setup_file', './preproc/setup.py',  # for gdal installation on the cloud -- see CUSTOM_COMMANDS in setup.py\n",
    "                               '--staging_location', 'gs://{0}/landcover/staging'.format(BUCKET),\n",
    "                               '--temp_location', 'gs://{0}/landcover/temp'.format(BUCKET)])\n",
    "        \n",
    "  print ml.sdk_location\n",
    "  imgsize = 16384 # of full image\n",
    "  #pixel_predictions = np.zeros(shape=(imgsize, imgsize), dtype=np.float32)\n",
    "  #print 'in-memory array created ...'\n",
    "  \n",
    "  (pipeline \n",
    "     | beam.Read(beam.io.TextFileSource(INPUT))\n",
    "     | beam.Map(lambda line: eval(line))\n",
    "     | beam.Map(lambda s: (s['key'].split(',')[0], s) )  # row, struct\n",
    "     | beam.GroupByKey()\n",
    "     | beam.SmallestPerKey(imgsize)\n",
    "     #| beam.Map(lambda s: set_pixel_from(pixel_predictions, s))\n",
    "  ) #\n",
    "   \n",
    "  pipeline.run()\n",
    "  write_geotiff(pixel_predictions, 'gs://cloud-training-demos-ml/landcover/prediction/landcover.TIF')\n",
    "  \n",
    "create_downscaled()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copyright 2016 Google Inc. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
