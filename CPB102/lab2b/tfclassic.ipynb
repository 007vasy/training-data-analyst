{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 2b. Working with low-level TensorFlow </h1>\n",
    "\n",
    "This notebook is Lab2b of CPB 102, Google's course on Machine Learning using Cloud ML.\n",
    "\n",
    "In this notebook, we will work with relatively low-level TensorFlow functions to implement a linear regression model. We will use this notebook to demonstrate early stopping -- a technique whereby training is stopped once the error on the validation dataset starts to increase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datalab.bigquery as bq\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to read data and compute error is the same as Lab2a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickuplon</th>\n",
       "      <th>pickuplat</th>\n",
       "      <th>dropofflon</th>\n",
       "      <th>dropofflat</th>\n",
       "      <th>passengers</th>\n",
       "      <th>fare_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-73.992050</td>\n",
       "      <td>40.751380</td>\n",
       "      <td>-73.954217</td>\n",
       "      <td>40.766692</td>\n",
       "      <td>2</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-73.993046</td>\n",
       "      <td>40.728159</td>\n",
       "      <td>-73.988222</td>\n",
       "      <td>40.731995</td>\n",
       "      <td>1</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-73.955591</td>\n",
       "      <td>40.782526</td>\n",
       "      <td>-73.972944</td>\n",
       "      <td>40.751067</td>\n",
       "      <td>1</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-73.964290</td>\n",
       "      <td>40.773350</td>\n",
       "      <td>-73.965440</td>\n",
       "      <td>40.755430</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-73.969442</td>\n",
       "      <td>40.797912</td>\n",
       "      <td>-73.982227</td>\n",
       "      <td>40.765247</td>\n",
       "      <td>1</td>\n",
       "      <td>9.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pickuplon  pickuplat  dropofflon  dropofflat  passengers  fare_amount\n",
       "0 -73.992050  40.751380  -73.954217   40.766692           2         16.5\n",
       "1 -73.993046  40.728159  -73.988222   40.731995           1          3.3\n",
       "2 -73.955591  40.782526  -73.972944   40.751067           1         10.5\n",
       "3 -73.964290  40.773350  -73.965440   40.755430           1         10.0\n",
       "4 -73.969442  40.797912  -73.982227   40.765247           1          9.7"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_dataset(filename):\n",
    "  return pd.read_csv(filename, header=None, names=['pickuplon','pickuplat','dropofflon','dropofflat','passengers','fare_amount'])\n",
    "\n",
    "df_train = read_dataset('../lab1a/taxi-train.csv')\n",
    "df_valid = read_dataset('../lab1a/taxi-valid.csv')\n",
    "df_test = read_dataset('../lab1a/taxi-test.csv')\n",
    "df_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FEATURE_COLS = np.arange(0,5)\n",
    "TARGET_COL   = 'fare_amount'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_rmse(actual, predicted):\n",
    "  return np.sqrt(np.mean((actual-predicted)**2))\n",
    "\n",
    "def print_rmse(model):\n",
    "  print \"Train RMSE = {0}\".format(compute_rmse(df_train[TARGET_COL], model.predict(df_train.iloc[:,FEATURE_COLS].values)))\n",
    "  print \"Valid RMSE = {0}\".format(compute_rmse(df_valid[TARGET_COL], model.predict(df_valid.iloc[:,FEATURE_COLS].values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Linear Regression </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1 train_error=10.4820785343 valid_err=14.2267043843\n",
      "Model written to /tmp/trained_model-1\n",
      "iter=101 train_error=9.32254544658 valid_err=12.5810729815\n",
      "Model written to /tmp/trained_model-101\n",
      "iter=201 train_error=8.40892708362 valid_err=11.2887527437\n",
      "Model written to /tmp/trained_model-201\n",
      "iter=301 train_error=7.73882045409 valid_err=10.3480562986\n",
      "Model written to /tmp/trained_model-301\n",
      "iter=401 train_error=7.28564938334 valid_err=9.72136243594\n",
      "Model written to /tmp/trained_model-401\n",
      "iter=501 train_error=7.00566281335 valid_err=9.34426825905\n",
      "Model written to /tmp/trained_model-501\n",
      "iter=601 train_error=6.8483815456 valid_err=9.14170238513\n",
      "Model written to /tmp/trained_model-601\n",
      "iter=701 train_error=6.76818062579 valid_err=9.04606913652\n",
      "Model written to /tmp/trained_model-701\n",
      "iter=801 train_error=6.73106733998 valid_err=9.00769772836\n",
      "Model written to /tmp/trained_model-801\n",
      "iter=901 train_error=6.71548417006 valid_err=8.99584805965\n",
      "Model written to /tmp/trained_model-901\n",
      "iter=1001 train_error=6.70955307584 valid_err=8.99426016298\n",
      "Model written to /tmp/trained_model-1001\n",
      "iter=1101 train_error=6.7075081229 valid_err=8.99561124031\n",
      "Early stop!\n"
     ]
    }
   ],
   "source": [
    "predictors = df_train.iloc[:,FEATURE_COLS].values\n",
    "targets = df_train[TARGET_COL].values\n",
    "prev_valid_error = 10000 # huge number\n",
    "modelprefix = '/tmp/trained_model'\n",
    "with tf.Session() as sess:\n",
    "  npredictors = len(FEATURE_COLS)\n",
    "  noutputs = 1\n",
    "  feature_data = tf.placeholder(\"float\", [None, npredictors])\n",
    "  target_data = tf.placeholder(\"float\", [None, noutputs])\n",
    "  weights = tf.Variable(tf.truncated_normal([npredictors, noutputs], stddev=0.01))\n",
    "  biases = tf.Variable(tf.ones([noutputs]))\n",
    "  model = (tf.matmul(feature_data, weights) + biases) # LINEAR REGRESSION\n",
    "  cost = tf.nn.l2_loss(model - target_data) # Square Error, not RMSE\n",
    "  saver = tf.train.Saver({'weights' : weights, 'biases' : biases})\n",
    "    \n",
    "  training_step = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(cost)\n",
    "  tf.initialize_all_variables().run()\n",
    "  for iter in xrange(0, 10000):\n",
    "    _, trainerr = sess.run([training_step, cost], feed_dict = {\n",
    "        feature_data : predictors,\n",
    "        target_data : targets.reshape(len(predictors), noutputs)\n",
    "      })\n",
    "    if (iter%100 == 1):\n",
    "      # early stop if validation error doesn't keep dropping\n",
    "      preds = sess.run(model, feed_dict = {feature_data : df_valid.iloc[:,FEATURE_COLS].values})\n",
    "      trmse = np.sqrt(trainerr/len(predictors))\n",
    "      vrmse = compute_rmse(df_valid[TARGET_COL], preds[0])      \n",
    "      print 'iter={0} train_error={1} valid_err={2}'.format(iter, trmse, vrmse)\n",
    "      if vrmse > prev_valid_error:\n",
    "         print \"Early stop!\"\n",
    "         break  # out of iteration loop\n",
    "      else:\n",
    "         prev_valid_error = vrmse\n",
    "         # save the model so that we can read it\n",
    "         modelfile = saver.save(sess, modelprefix, global_step=iter)\n",
    "         print 'Model written to {0}'.format(modelfile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the training error can be driven down very low, but it doesn't actually reduce the validation error.  To help prevent over-fitting, the loop above makes use of \"early-stopping\", to stop the training when the validation error starts to increase.  In tf.learn, we didn't pass in a validation dataset, but we got similar performance on the validation set -- that's because tf.learn uses a different technique called regularization to help prevent over-fitting.\n",
    "\n",
    "Early stopping and regularization are not that critical in linear regression (because the model is quite simple), but are crucial once you start creating deep neural networks where there are thousands of weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
