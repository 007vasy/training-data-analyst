{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Structured Data Solution </h1>\n",
    "\n",
    "In this notebook, we will use the structured data package in Datalab to build a model to predict taxifares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "PROJECT = 'cloud-training-demos'    # CHANGE THIS\n",
    "BUCKET = 'cloud-training-demos-ml'  # CHANGE THIS\n",
    "REGION = 'us-central1' # CHANGE THIS\n",
    "\n",
    "os.environ['PROJECT'] = PROJECT # for bash\n",
    "os.environ['BUCKET'] = BUCKET # for bash\n",
    "os.environ['REGION'] = REGION # for bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%bash\n",
    "echo \"project=$PROJECT\"\n",
    "echo \"bucket=$BUCKET\"\n",
    "echo \"region=$REGION\"\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION\n",
    "gcloud beta ml init-project -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import datalab.ml as ml\n",
    "import google.cloud.ml as cml\n",
    "import datalab_solutions.structured_data as sd\n",
    "from tensorflow.python.lib.io import file_io\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "print('tf ' + str(tf.__version__))\n",
    "print('sd ' + str(sd.__version__))\n",
    "print('cml ' + str(cml.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INDIR = '../feateng/sample'\n",
    "OUTDIR = '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Set up schema file </h2>\n",
    "\n",
    "Schema of training/test. Same format as BigQuery.  STRING/INTEGER/FLOAT only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%writefile taxifare.json\n",
    "[\n",
    "    {\n",
    "        \"mode\": \"NULLABLE\",\n",
    "        \"name\": \"fare_amount\",\n",
    "        \"type\": \"FLOAT\"\n",
    "    }, \n",
    "    {\n",
    "        \"mode\": \"NULLABLE\",\n",
    "        \"name\": \"dayofweek\",\n",
    "        \"type\": \"STRING\"\n",
    "    },\n",
    "    {\n",
    "        \"mode\": \"NULLABLE\",\n",
    "        \"name\": \"hourofday\",\n",
    "        \"type\": \"STRING\"\n",
    "    },\n",
    "    {\n",
    "        \"mode\": \"NULLABLE\",\n",
    "        \"name\": \"pickuplon\",\n",
    "        \"type\": \"FLOAT\"\n",
    "    },\n",
    "    {\n",
    "        \"mode\": \"NULLABLE\",\n",
    "        \"name\": \"pickuplat\",\n",
    "        \"type\": \"FLOAT\"\n",
    "    },\n",
    "    {\n",
    "        \"mode\": \"NULLABLE\",\n",
    "        \"name\": \"dropofflon\",\n",
    "        \"type\": \"FLOAT\"\n",
    "    },\n",
    "    {\n",
    "        \"mode\": \"NULLABLE\",\n",
    "        \"name\": \"dropofflat\",\n",
    "        \"type\": \"FLOAT\"\n",
    "    },\n",
    "    {\n",
    "        \"mode\": \"NULLABLE\",\n",
    "        \"name\": \"passengers\",\n",
    "        \"type\": \"FLOAT\"\n",
    "    },\n",
    "    {\n",
    "        \"mode\": \"REQUIRED\",\n",
    "        \"name\": \"key\",\n",
    "        \"type\": \"STRING\"\n",
    "    } \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Preprocessing </h2>\n",
    "\n",
    "The first step of preprocessing is to compute the min, max, etc. for scaling purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm -rf taxi_preproc taxi_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_csv = ml.CsvDataSet(\n",
    "  file_pattern=os.path.join(INDIR, 'train*'),\n",
    "  schema_file=os.path.join(OUTDIR, 'taxifare.json'))\n",
    "sd.local_preprocess(\n",
    "  dataset=train_csv,\n",
    "  output_dir=os.path.join(OUTDIR, 'taxi_preproc'),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second step is to specify the feature columns and transformations.  The target and key transforms are required. Everything else is optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transforms = {\n",
    "  \"fare_amount\": {\"transform\": \"target\"},\n",
    "  \"key\": {\"transform\": \"key\"}, \n",
    "  \"dayofweek\": {\"transform\": \"one_hot\"},\n",
    "  \"hourofday\": {\"transform\": \"embedding\", \"embedding_dim\": 2}, # group-combine the hour\n",
    "}\n",
    "file_io.write_string_to_file(os.path.join(OUTDIR, 'taxi_preproc/transforms.json'),\n",
    "                             json.dumps(transforms, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ls taxi_preproc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Local Training and prediction </h2>\n",
    "\n",
    "Train using the preproprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_csv = ml.CsvDataSet(\n",
    "  file_pattern=os.path.join(INDIR, 'valid*'),\n",
    "  schema_file=os.path.join('.', 'taxifare.json'))\n",
    "\n",
    "shutil.rmtree('./taxi_trained', ignore_errors=True)\n",
    "sd.local_train(\n",
    "  train_dataset=train_csv,\n",
    "  eval_dataset=eval_csv,\n",
    "  preprocess_output_dir=os.path.join(OUTDIR, 'taxi_preproc'),\n",
    "  transforms=os.path.join(OUTDIR, 'taxi_preproc/transforms.json'),\n",
    "  output_dir=os.path.join(OUTDIR, 'taxi_trained'),\n",
    "  model_type='dnn_regression',\n",
    "  max_steps=2500,\n",
    "  layer_sizes=[64, 4]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation_model  model  train\r\n"
     ]
    }
   ],
   "source": [
    "!ls taxi_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting local prediction.\n",
      "Local prediction done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_from_input</th>\n",
       "      <th>predicted_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>row_01</td>\n",
       "      <td>11.257042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>row_02</td>\n",
       "      <td>11.257042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>row_03</td>\n",
       "      <td>11.257042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>row_04</td>\n",
       "      <td>11.257042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>row_05</td>\n",
       "      <td>11.257042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>row_06</td>\n",
       "      <td>11.257042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>row_07</td>\n",
       "      <td>11.257042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>row_08</td>\n",
       "      <td>11.257042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>row_09</td>\n",
       "      <td>11.257042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>row_10</td>\n",
       "      <td>11.257042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  key_from_input  predicted_target\n",
       "0         row_01         11.257042\n",
       "1         row_02         11.257042\n",
       "2         row_03         11.257042\n",
       "3         row_04         11.257042\n",
       "4         row_05         11.257042\n",
       "5         row_06         11.257042\n",
       "6         row_07         11.257042\n",
       "7         row_08         11.257042\n",
       "8         row_09         11.257042\n",
       "9         row_10         11.257042"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd.local_predict(\n",
    "  training_ouput_dir=os.path.join(OUTDIR, 'taxi_trained'),\n",
    "  data=['Sun,0,-73.984685,40.769262,-73.991065,40.728145,5.0,row_01',\n",
    "        'Sun,0,-74.006927,40.739993,-73.950025,40.773403,1.0,row_02',\n",
    "        'Sun,0,-73.977345,40.779387,-73.97615,40.778867,1.0,row_03',\n",
    "        'Sun,0,-73.97136,40.794413,-73.99623,40.74524,1.0,row_04',\n",
    "        'Sun,0,-73.997642,40.763853,-73.99485,40.750282,1.0,row_05',\n",
    "        'Sun,0,-74.004538,40.742202,-73.955823,40.773485,1.0,row_06',\n",
    "        'Sun,0,-74.000589,40.73731,-73.985902,40.692725,1.0,row_07',\n",
    "        'Sun,0,-73.995432,40.72114,-73.992403,40.719745,1.0,row_08',\n",
    "        'Sun,0,-73.945033,40.779203,-73.952037,40.766802,1.0,row_09',\n",
    "        'Sun,0,-73.968592,40.693262,-73.99231,40.694317,1.0,row_10']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shutil.rmtree('./batch_predict', ignore_errors=True)\n",
    "sd.local_batch_predict(\n",
    "  training_ouput_dir=os.path.join(OUTDIR, 'taxi_trained'),\n",
    "  prediction_input_file=os.path.join(INDIR, 'valid*'),\n",
    "  output_dir=os.path.join(OUTDIR, 'batch_predict'),\n",
    "  output_format='csv',\n",
    "  mode='prediction'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ls batch_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Cloud preprocessing and training </h2>\n",
    "\n",
    "In the above cells, change INDIR and OUTDIR to be GCS.\n",
    "\n",
    "Change the calls from local_predict to cloud_predict. That's it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2016 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
